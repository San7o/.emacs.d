;; -*- coding: utf-8-emacs; -*-
(setq nnrss-group-data '((20 (26595 3901 213214 956000) "https://alexschroeder.ch/view/2025-03-25-down" "2025-03-25 Down down down" nil "Tue, 25 Mar 2025 12:14:28 +0000" "<h1 id=\"2025-03-25-down-down-down\">2025-03-25 Down down down</h1>
<p>Israel is continuing its genocide against the Palestinians.
<a href=\"https://en.wikipedia.org/wiki/Francesca_Albanese\">Fanscesca Albanese</a> is saying all the right things but people keep arming and Israel.</p>
<blockquote>
<p>There are ``reasonable grounds'' to believe that Israel is committing genocide against Palestinians in Gaza, the UN Special Rapporteur on the situation of human rights in the Occupied Palestinian Territories said on Tuesday. - <a href=\"https://news.un.org/en/story/2024/03/1147976\">Rights expert finds ‚Äòreasonable grounds‚Äô genocide is being committed in Gaza</a></p>
</blockquote>
<p>In a world where there are no consequences, sociopaths go on a rampage.</p>
<p>Russia is continuing its <a href=\"https://en.wikipedia.org/wiki/Russo-Ukrainian_War\">invasion of Ukraine</a>.
I'm following <a href=\"https://meduza.io/en\">Meduza</a> for news from Russia.
I don't know what to do. But seizing Russian assets and supporting Ukraine should be at the obvious thing to do.
Remember the news in 2014:</p>
<blockquote>
<p>Twenty years ago, Ukraine gave up its nuclear weapons in exchange for security guarantees from Russia and the West. Today Kyiv feels betrayed - and not merely by Moscow. - <a href=\"https://www.dw.com/en/ukraines-forgotten-security-guarantee-the-budapest-memorandum/a-18111097\">Ukraine's forgotten security guarantee</a>, by Roman Goncharenko / bw, for DW</p>
</blockquote>
<p><a class=\"account\" href=\"https://agora.echelon.pl/users/kravietz\" title=\"@kravietz@agora.echelon.pl\">@kravietz</a> posted a link to the <a href=\"https://treaties.un.org/Pages/showDetails.aspx?objid=08000002803fe18a\">Treaty between Ukraine and the Russian Federation on the Ukrainian-Russian State border</a> (2003), including maps at a scale of 1:50,000. With Putin's signature.</p>
<p>In a world where there are no consequences, sociopaths keep going on a rampage.</p>
<p>The US federal government keeps collapsing. Soon, the federal state will be dismantled. I wonder if there will be a new (smaller?) union to rise from the ashes.</p>
<blockquote>
<p>As a result, he is asking the question beloved of so many right-wingers over the last century or so, which question we thought to have been resolved by the American Civil War, which is whether or not any form of federal organisation is actually required in North America. ‚Äì <a href=\"https://www.taxresearch.org.uk/Blog/2025/03/23/trumps-assault-on-the-usa-seeking-an-explanation/\">Trump‚Äôs assault on the USA: seeking an explanation</a>, by Richard Murphy (<a class=\"account\" href=\"https://mas.to/@RichardJMurphy\" title=\"@RichardJMurphy@mas.to\">@RichardJMurphy</a>)</p>
</blockquote>
<p>In a world where there are no consequences, sociopaths keep going on a rampage.</p>
<p>And I'm not even looking at the rest of the world.</p>
<p><a class=\"tag\" href=\"/search/?q=%23Politics\">#Politics</a> <a class=\"tag\" href=\"/search/?q=%23USA\">#USA</a> <a class=\"tag\" href=\"/search/?q=%23Russia\">#Russia</a> <a class=\"tag\" href=\"/search/?q=%23Ukraine\">#Ukraine</a> <a class=\"tag\" href=\"/search/?q=%23Palestine\">#Palestine</a></p>
" nil nil "74ba81f39d375d49f5c02e4993e2ee45") (19 (26595 3901 209425 265000) "https://alexschroeder.ch/view/2025-03-21-blumen" "2025-03-24 Blumenfotos" nil "Tue, 25 Mar 2025 12:35:52 +0000" "<h1 id=\"2025-03-24-blumenfotos\">2025-03-24 Blumenfotos</h1>
<p>I‚Äôve been taking pictures of flowers in spring‚Ä¶</p>
<p>Hanami!</p>
<p>I'm so happy to have these cherry blossoms in the school yard accross the road.</p>
<p>Japanische Bl√ºtenkirsche<br>
Prunus serrulata</p>
<p><img loading=\"lazy\" src=\"2025-03-21-blumen-1.jpg\" alt=\"\" /></p>
<p>I‚Äôm walking through the neighbourhood. Identifying flowers using Flora Incognita.</p>
<p>Scharbockskraut<br>
Ficaria verna</p>
<p><img loading=\"lazy\" src=\"2025-03-21-blumen-2.jpg\" alt=\"\" /></p>
<p>Chinesische Zierquitte<br>
Chaenomeles speciosa</p>
<p><img loading=\"lazy\" src=\"2025-03-21-blumen-3.jpg\" alt=\"\" /></p>
<p>GewoÃàhnliche Mahonie<br>
Berberis aquifolium</p>
<p><img loading=\"lazy\" src=\"2025-03-21-blumen-4.jpg\" alt=\"\" /></p>
<p>StaÃàngellose SchluÃàsselblume<br>
Primula acaulis</p>
<p><img loading=\"lazy\" src=\"2025-03-21-blumen-5.jpg\" alt=\"\" /></p>
<p>Wald-Veilchen<br>
Viola reichenbachiana</p>
<p><img loading=\"lazy\" src=\"2025-03-21-blumen-6.jpg\" alt=\"\" /></p>
<p>Dunkle Sternhyazinthe<br>
Scilla sardensis</p>
<p><img loading=\"lazy\" src=\"2025-03-21-blumen-7.jpg\" alt=\"\" /></p>
<p>FruÃàhlings-Krokus<br>
Crocus vernus</p>
<p><img loading=\"lazy\" src=\"2025-03-21-blumen-8.jpg\" alt=\"\" /></p>
<p>Busch-WindroÃàschen<br>
Anemone nemorosa</p>
<p><img loading=\"lazy\" src=\"2025-03-21-blumen-9.jpg\" alt=\"\" /></p>
<p>Sent from this nice bench overlooking an outer part of Z√ºrich.
I just like taking pictures of benches where I intend to sit moments later. üòÖ</p>
<p><img loading=\"lazy\" src=\"2025-03-21-blumen-10.jpg\" alt=\"\" /></p>
<p>Griechisches Blaukissen<br>
Aubrieta deltoidea</p>
<p><img loading=\"lazy\" src=\"2025-03-21-blumen-11.jpg\" alt=\"\" /></p>
<p>These flowers are all over the lawns in early spring!
Here it is again.</p>
<p>StaÃàngellose SchluÃàsselblume<br>
Primula acaulis</p>
<p><img loading=\"lazy\" src=\"2025-03-21-blumen-12.jpg\" alt=\"\" /></p>
<p>Like aubrieta, this one forms hanging carpets and I love that.</p>
<p>Immergr√ºne Schleifenblume<br>
Iberis sempervirens</p>
<p><img loading=\"lazy\" src=\"2025-03-21-blumen-13.jpg\" alt=\"\" /></p>
<p>And of course, the largest flowers in the area‚Ä¶</p>
<p>Tulpen-Magnolie<br>
Magnolia soulangeana</p>
<p><img loading=\"lazy\" src=\"2025-03-21-blumen-14.jpg\" alt=\"\" /></p>
<p>Riesen Schachtelhalm<br>
Equisetum telmateia</p>
<p><img loading=\"lazy\" src=\"2025-03-21-blumen-15.jpg\" alt=\"\" /></p>
<p>Balkan-Windr√∂schen<br>
Anemone blanda</p>
<p><img loading=\"lazy\" src=\"2025-03-21-blumen-16.jpg\" alt=\"\" /></p>
<p>Weisses Veilchen<br>
Viola alba</p>
<p><img loading=\"lazy\" src=\"2025-03-21-blumen-18.jpg\" alt=\"\" /></p>
<p>Gew√∂hnliches Greiskraut<br>
Senecio vulgaris</p>
<p><img loading=\"lazy\" src=\"2025-03-21-blumen-19.jpg\" alt=\"\" /></p>
<p>And again, the wonderful magnolia.</p>
<p>Tulpen-Magnolie<br>
Magnolia soulangeana</p>
<p><img loading=\"lazy\" src=\"2025-03-21-blumen-20.jpg\" alt=\"\" /></p>
<p>I thought chaenomeles was always red, but I guess not.
Here it is again.</p>
<p>Chinesische Zierquitte<br>
Chaenomeles speciosa</p>
<p><img loading=\"lazy\" src=\"2025-03-21-blumen-21.jpg\" alt=\"\" /></p>
<p>Gew√∂hnliche Kegelblume<br>
Puschkinia scilloides</p>
<p><img loading=\"lazy\" src=\"2025-03-21-blumen-24.jpg\" alt=\"\" /></p>
<p>Gefiederte Sockenblume<br>
Epimedium pinnatum</p>
<p><img loading=\"lazy\" src=\"2025-03-21-blumen-17.jpg\" alt=\"\" /></p>
<p>Not sure what this is. Some sort of prunus?</p>
<p><img loading=\"lazy\" src=\"2025-03-21-blumen-22.jpg\" alt=\"\" /></p>
<p>The contrast between those trees and the road construction works is poignant.</p>
<p><img loading=\"lazy\" src=\"2025-03-21-blumen-23.jpg\" alt=\"\" /></p>
<p>And back to cherry trees. üòç</p>
<p><img loading=\"lazy\" src=\"2025-03-21-blumen-25.jpg\" alt=\"\" /></p>
<p><a class=\"tag\" href=\"/search/?q=%23Pictures\">#Pictures</a> <a class=\"tag\" href=\"/search/?q=%23Flowers\">#Flowers</a> <a class=\"tag\" href=\"/search/?q=%23Plants\">#Plants</a></p>
<p><strong>2025-03-25</strong>. And on the balcony, too.</p>
<p>Goldlack<br>
Erysimum cheiri</p>
<p><img loading=\"lazy\" src=\"2025-03-21-blumen-26.jpg\" alt=\"\" /></p>
<p>Armenische Traubenhyazinthe<br>
Muscari armeniacum</p>
<p><img loading=\"lazy\" src=\"2025-03-21-blumen-27.jpg\" alt=\"\" /></p>
" nil nil "ccc8b3ae9e87be79af76a02e17126c5b") (18 (26594 28600 625541 32000) "https://alexschroeder.ch/view/2025-03-25-down" "2025-03-25 Down down down" nil "Tue, 25 Mar 2025 09:56:14 +0000" "<h1 id=\"2025-03-25-down-down-down\">2025-03-25 Down down down</h1>
<p>Israel is continuing its genocide against the Palestinians.
<a href=\"https://en.wikipedia.org/wiki/Francesca_Albanese\">Fanscesca Albanese</a> is saying all the right things but people keep arming and Israel.</p>
<blockquote>
<p>There are ``reasonable grounds'' to believe that Israel is committing genocide against Palestinians in Gaza, the UN Special Rapporteur on the situation of human rights in the Occupied Palestinian Territories said on Tuesday. - <a href=\"https://news.un.org/en/story/2024/03/1147976\">Rights expert finds ‚Äòreasonable grounds‚Äô genocide is being committed in Gaza</a></p>
</blockquote>
<p>In a world where there are no consequences, sociopaths go on a rampage.</p>
<p>Russia is continuing its <a href=\"https://en.wikipedia.org/wiki/Russo-Ukrainian_War\">invasion of Ukraine</a>.
I'm following <a href=\"https://meduza.io/en\">Meduza</a> for news from Russia.
I don't know what to do. But seizing Russian assets and supporting Ukraine should be at the obvious thing to do.
Remember the news in 2014:</p>
<blockquote>
<p>Twenty years ago, Ukraine gave up its nuclear weapons in exchange for security guarantees from Russia and the West. Today Kyiv feels betrayed - and not merely by Moscow. - <a href=\"https://www.dw.com/en/ukraines-forgotten-security-guarantee-the-budapest-memorandum/a-18111097\">Ukraine's forgotten security guarantee</a>, by Roman Goncharenko / bw, for DW</p>
</blockquote>
<p>In a world where there are no consequences, sociopaths keep going on a rampage.</p>
<p>The US federal government keeps collapsing. Soon, the federal state will be dismantled. I wonder if there will be a new (smaller?) union to rise from the ashes.</p>
<blockquote>
<p>As a result, he is asking the question beloved of so many right-wingers over the last century or so, which question we thought to have been resolved by the American Civil War, which is whether or not any form of federal organisation is actually required in North America. ‚Äì <a href=\"https://www.taxresearch.org.uk/Blog/2025/03/23/trumps-assault-on-the-usa-seeking-an-explanation/\">Trump‚Äôs assault on the USA: seeking an explanation</a>, by Richard Murphy (<a class=\"account\" href=\"https://mas.to/@RichardJMurphy\" title=\"@RichardJMurphy@mas.to\">@RichardJMurphy</a>)</p>
</blockquote>
<p>In a world where there are no consequences, sociopaths keep going on a rampage.</p>
<p>And I'm not even looking at the rest of the world.</p>
<p><a class=\"tag\" href=\"/search/?q=%23Politics\">#Politics</a> <a class=\"tag\" href=\"/search/?q=%23USA\">#USA</a> <a class=\"tag\" href=\"/search/?q=%23Russia\">#Russia</a> <a class=\"tag\" href=\"/search/?q=%23Ukraine\">#Ukraine</a> <a class=\"tag\" href=\"/search/?q=%23Palestine\">#Palestine</a></p>
" nil nil "a48c81eba446e4b3dff9cb0233abb3c0") (17 (26593 44716 885045 253000) "https://alexschroeder.ch/view/2025-03-21-blumen" "2025-03-24 Blumenfotos" nil "Mon, 24 Mar 2025 18:50:26 +0000" "<h1 id=\"2025-03-24-blumenfotos\">2025-03-24 Blumenfotos</h1>
<p>I‚Äôve been taking pictures of flowers in spring‚Ä¶</p>
<p>Hanami!</p>
<p>I'm so happy to have these cherry blossoms in the school yard accross the road.</p>
<p>Japanische Bl√ºtenkirsche<br>
Prunus serrulata</p>
<p><img loading=\"lazy\" src=\"2025-03-21-blumen-1.jpg\" alt=\"\" /></p>
<p>I‚Äôm walking through the neighbourhood. Identifying flowers using Flora Incognita.</p>
<p>Scharbockskraut<br>
Ficaria verna</p>
<p><img loading=\"lazy\" src=\"2025-03-21-blumen-2.jpg\" alt=\"\" /></p>
<p>Chinesische Zierquitte<br>
Chaenomeles speciosa</p>
<p><img loading=\"lazy\" src=\"2025-03-21-blumen-3.jpg\" alt=\"\" /></p>
<p>GewoÃàhnliche Mahonie<br>
Berberis aquifolium</p>
<p><img loading=\"lazy\" src=\"2025-03-21-blumen-4.jpg\" alt=\"\" /></p>
<p>StaÃàngellose SchluÃàsselblume<br>
Primula acaulis</p>
<p><img loading=\"lazy\" src=\"2025-03-21-blumen-5.jpg\" alt=\"\" /></p>
<p>Wald-Veilchen<br>
Viola reichenbachiana</p>
<p><img loading=\"lazy\" src=\"2025-03-21-blumen-6.jpg\" alt=\"\" /></p>
<p>Dunkle Sternhyazinthe<br>
Scilla sardensis</p>
<p><img loading=\"lazy\" src=\"2025-03-21-blumen-7.jpg\" alt=\"\" /></p>
<p>FruÃàhlings-Krokus<br>
Crocus vernus</p>
<p><img loading=\"lazy\" src=\"2025-03-21-blumen-8.jpg\" alt=\"\" /></p>
<p>Busch-WindroÃàschen<br>
Anemone nemorosa</p>
<p><img loading=\"lazy\" src=\"2025-03-21-blumen-9.jpg\" alt=\"\" /></p>
<p>Sent from this nice bench overlooking an outer part of Z√ºrich.
I just like taking pictures of benches where I intend to sit moments later. üòÖ</p>
<p><img loading=\"lazy\" src=\"2025-03-21-blumen-10.jpg\" alt=\"\" /></p>
<p>Griechisches Blaukissen<br>
Aubrieta deltoidea</p>
<p><img loading=\"lazy\" src=\"2025-03-21-blumen-11.jpg\" alt=\"\" /></p>
<p>These flowers are all over the lawns in early spring!
Here it is again.</p>
<p>StaÃàngellose SchluÃàsselblume<br>
Primula acaulis</p>
<p><img loading=\"lazy\" src=\"2025-03-21-blumen-12.jpg\" alt=\"\" /></p>
<p>Like aubrieta, this one forms hanging carpets and I love that.</p>
<p>Immergr√ºne Schleifenblume<br>
Iberis sempervirens</p>
<p><img loading=\"lazy\" src=\"2025-03-21-blumen-13.jpg\" alt=\"\" /></p>
<p>And of course, the largest flowers in the area‚Ä¶</p>
<p>Tulpen-Magnolie<br>
Magnolia soulangeana</p>
<p><img loading=\"lazy\" src=\"2025-03-21-blumen-14.jpg\" alt=\"\" /></p>
<p>Riesen Schachtelhalm<br>
Equisetum telmateia</p>
<p><img loading=\"lazy\" src=\"2025-03-21-blumen-15.jpg\" alt=\"\" /></p>
<p>Balkan-Windr√∂schen<br>
Anemone blanda</p>
<p><img loading=\"lazy\" src=\"2025-03-21-blumen-16.jpg\" alt=\"\" /></p>
<p>Weisses Veilchen<br>
Viola alba</p>
<p><img loading=\"lazy\" src=\"2025-03-21-blumen-18.jpg\" alt=\"\" /></p>
<p>Gew√∂hnliches Greiskraut<br>
Senecio vulgaris</p>
<p><img loading=\"lazy\" src=\"2025-03-21-blumen-19.jpg\" alt=\"\" /></p>
<p>And again, the wonderful magnolia.</p>
<p>Tulpen-Magnolie<br>
Magnolia soulangeana</p>
<p><img loading=\"lazy\" src=\"2025-03-21-blumen-20.jpg\" alt=\"\" /></p>
<p>I thought chaenomeles was always red, but I guess not.
Here it is again.</p>
<p>Chinesische Zierquitte<br>
Chaenomeles speciosa</p>
<p><img loading=\"lazy\" src=\"2025-03-21-blumen-21.jpg\" alt=\"\" /></p>
<p>Gew√∂hnliche Kegelblume<br>
Puschkinia scilloides</p>
<p><img loading=\"lazy\" src=\"2025-03-21-blumen-24.jpg\" alt=\"\" /></p>
<p>Gefiederte Sockenblume<br>
Epimedium pinnatum</p>
<p><img loading=\"lazy\" src=\"2025-03-21-blumen-17.jpg\" alt=\"\" /></p>
<p>Not sure what this is. Some sort of prunus?</p>
<p><img loading=\"lazy\" src=\"2025-03-21-blumen-22.jpg\" alt=\"\" /></p>
<p>The contrast between those trees and the road construction works is poignant.</p>
<p><img loading=\"lazy\" src=\"2025-03-21-blumen-23.jpg\" alt=\"\" /></p>
<p>And back to cherry trees. üòç</p>
<p><img loading=\"lazy\" src=\"2025-03-21-blumen-25.jpg\" alt=\"\" /></p>
<p><a class=\"tag\" href=\"/search/?q=%23Pictures\">#Pictures</a> <a class=\"tag\" href=\"/search/?q=%23Flowers\">#Flowers</a> <a class=\"tag\" href=\"/search/?q=%23Plants\">#Plants</a></p>
" nil nil "df28d4102ed683e469a320327bbb7849") (16 (26593 44716 884587 864000) "https://alexschroeder.ch/view/2025-03-21-defence-summary" "2025-03-21 A summary of my bot defence systems" nil "Sat, 22 Mar 2025 12:03:34 +0000" "<h1 id=\"2025-03-21-a-summary-of-my-bot-defence-systems\">2025-03-21 A summary of my bot defence systems</h1>
<p>If you've followed my <a href=\"Butlerian_Jihad\">Butlerian Jihad</a> pages, you know that I'm constantly fiddling with the setup.
Each page got written in the middle of an attack as I'm trying to save my sites, documenting as I go along. But if
you're looking for an overview, there is nothing to see. It's all over the place. Since the topic has gained some
traction in recent days, I'm going to assemble all the things I do on this page.</p>
<p>Here's Drew DeVault complaining about the problem that system administrators have been facing for a while, now:</p>
<blockquote>
<p>If you think these crawlers respect <code>robots.txt</code> then you are several assumptions of good faith removed from reality. These bots crawl everything they can find, <code>robots.txt</code> be damned, including expensive endpoints like git blame, every page of every git log, and every commit in every repo, and they do so using random User-Agents that overlap with end-users and come from tens of thousands of IP addresses ‚Äì mostly residential, in unrelated subnets, each one making no more than one HTTP request over any time period we tried to measure ‚Äì actively and maliciously adapting and blending in with end-user traffic and avoiding attempts to characterize their behavior or block their traffic. - <a href=\"https://drewdevault.com/2025/03/17/2025-03-17-Stop-externalizing-your-costs-on-me.html\">Please stop externalizing your costs directly into my face</a>, by Drew DeVault, for SourceHut</p>
</blockquote>
<p>I had read some similar reports before, on fedi, but this one links to quite a few of them: <a href=\"https://thelibre.news/foss-infrastructure-is-under-attack-by-ai-companies/\">FOSS infrastructure is under attack by AI companies</a>, by Niccol√≤ Venerandi, for LibreNews.</p>
<p>I'm going to skip the defences against spam as spam hasn't been a problem in recent months, surprisingly.</p>
<p>The first defence against bots is <code>robots.txt</code>. All well-behaving bots should read it every now and then and then either stop crawling
the site or slow down.</p>
<p>Let's look at the file <a href=\"https://www.emacswiki.org/robots.txt\">for Emacs Wiki</a>.</p>
<p>If I find that there are lot of requests from a particular user agent that looks like bot, and it has a URL where I can find instructions
for how to address it in <code>robots.txt</code>, this is what I do. I tell them to stop crawling the entire site. Most of these are search engine optimizers, brand awareness monitors and other such creeps.</p>
<p>The file also tells all well-behaving crawlers to slow down to a glacial tempo and it lists all the expensive endpoints that they should not be crawling at all. Conversely, this means that any bot that still crawls those URLs is a misbehaving bot and deserves to be blocked.</p>
<p>Worth noting, perhaps, that ``an expensive endpoint'' means a URL that runs some executable to do something complicated, resulting in an answer that's always different. If the URL causes the web server to run a CGI script, for example, the request loads Perl, loads a script, loads all its libraries, compiles it all, runs it once, and answers with the request with the output. And since the answer is dynamic, it can't very well be cached, or additional complexity needs to be introduced and even more resources need to be allocated and paid for. In short, an expensive end-point is like loading an app. It's slow but useful, if done rarely. So you'd do this for a human, for example. It's a disaster if bots swarm all over the site, clicking on every link.</p>
<p>It's also worth noting that not all my sites have the same expensive endpoints and so the second half of <code>robots.txt</code> can vary. Which makes maintenance of the first half a chore. I have a little script that allows me to add one bot to ``all'' the files, but it's annoying to have to do that. And I recently just copied a list from an <a href=\"https://robotstxt.com/ai\">AI / LLM User-Agents: Blocking Guide</a>.</p>
<p>I use Apache as my web-server and I have a bunch of global configuration files to handle misbehaving bots and crawlers.</p>
<p>This example blocks fediverse agents from accessing my site. That's because whenever anybody post a URL to one of my sites, within the next
60 seconds, all the servers with users getting a copy of the URL will fetch a preview. That means hundreds of hits. This is particularly
obnoxious for expensive endpoints. This response here tells them that they are forbidden from accessing the page.</p>
<pre><code># Fediverse instances asking for previews: protect the expensive endpoints
RewriteCond %{REQUEST_URI} /(wiki|download|food|paper|hug|helmut|input|korero|check|radicale|say|mojo|software)
RewriteCond %{HTTP_USER_AGENT} Mastodon|Friendica|Pleroma [nocase]
# then it's forbidden
RewriteRule ^(.*)$ - [forbidden,last]
</code></pre>
<p>These are the evil bots that self-identify as a bot but don't seem to heed the <code>robots.txt</code> files. These are all told that whatever page they were looking for, it's now gone (410). And if there's a human looking at the output, it even links to an explanation. Adding new user agents to this list is annoying because I need to connect as root and restart the web server after making any changes.</p>
<pre><code># SEO bots, borked feed services and other shit
RewriteCond \"%{HTTP_USER_AGENT}\" \"academicbotrtu|ahrefsbot|amazonbot|awariobot|bitsightbot|blexbot|bytespider|dataforseobot|discordbot|domainstatsbot|dotbot|elisabot|eyemonit|facebot|linkfluence|magpie-crawler|megaindex|mediatoolkitbot|mj12bot|newslitbot|paperlibot|pcore|petalbot|pinterestbot|seekportbot|semanticscholarbot|semrushbot|semanticbot|seokicks-robot|siteauditbot|startmebot|summalybot|synapse|trendictionbot|twitterbot|wiederfrei|yandexbot|zoominfobot|velenpublicwebcrawler|gpt|\\bads|feedburner|brandwatch|openai|facebookexternalhit|yisou|docspider\" [nocase]
RewriteRule ^ https://alexschroeder.ch/nobots [redirect=410,last]
</code></pre>
<p>For some of my sites, I disallow all user agents containing the words ``bot'', ``crawler'', ``spider'', ``ggpht'' or ``gpt'' with the exception of ``archivebot'' and ``wibybot'' because these two bots I want to give access. Again, these bots are all told that whatever page they were looking for, it's now gone (410).</p>
<pre><code># Private sites block all bots and crawlers. This list does no include
# social.alexschroeder.ch, communitywiki.org, www.emacswiki.org,
# oddmuse.org, orientalisch.info, korero.org.
RewriteCond \"%{HTTP_HOST}\" \"^((src\\.)?alexschroeder\\.ch|flying-carpet\\.ch|next\\.oddmuse\\.org|((chat|talk)\\.)?campaignwiki\\.org|((archive|vault|toki|xn--vxagggm5c)\\.)?transjovian\\.org)$\" [nocase]
RewriteCond \"%{HTTP_USER_AGENT}\" \"!archivebot|^gwene|wibybot\" [nocase]
RewriteCond \"%{HTTP_USER_AGENT}\" \"bot|crawler|spider|ggpht|gpt\" [nocase]
RewriteRule ^ https://alexschroeder.ch/nobots [redirect=410,last]
</code></pre>
<p>I also eliminate a lot of bots looking for PHP endpoints. I can do this because I know that I don't have any PHP application installed.</p>
<pre><code># Deny all idiots that are looking for borked PHP applications
RewriteRule \\.php$ https://alexschroeder.ch/nobots [redirect=410,last]
</code></pre>
<p>There's also one particular image scraper that's using a unique string in its user agent.</p>
<pre><code># Deny the image scraper
# https://imho.alex-kunz.com/2024/02/25/block-this-shit/
RewriteCond \"%{HTTP_USER_AGENT}\" \"Firefox/72.0\" [nocase]
RewriteRule ^ https://alexschroeder.ch/nobots [redirect=410,last]
</code></pre>
<p>Next, all requests get logged by Apache in the <code>access.log</code> file. I use <code>fail2ban</code> to check this logfile. This is somewhat interesting
because <code>fail2ban</code> is usually used to check for failed ssh login attempts. Those IP numbers that fail to login in a few times are banned.
What I'm doing is I wrote a filter that treats every hit on the web server as a ``failed login attempt''.</p>
<p>This is the filter:</p>
<pre><code>[Definition]
# Most sites in the logfile count! What doesn't count is fedi.alexschroeder.ch, or chat.campaignwiki.org.
failregex = ^(www\\.)?(alexschroeder\\.ch|campaignwiki\\.org|communitywiki\\.org|emacswiki\\.org|flying-carpet\\.ch|korero\\.org|oddmuse\\.org|orientalisch\\.info):[0-9]+ <HOST>
# Except css files, images...
ignoreregex = ^[^\"]*\"(GET /(robots\\.txt |favicon\\.ico |[^/ \\\"]+\\.(css|js) |[^\\\"]*\\.(jpg|JPG|png|PNG) |css/|fonts/|pdfs/|txt/|pics/|export/|podcast/|1pdc/|static/|munin/|osr/|indie/|rpg/|face/|traveller/|hex-describe/|text-mapper/|contrib/pics/|roll/|alrik/|wiki/download/)|(OPTIONS|PROPFIND|REPORT) /radicale)
</code></pre>
<p>And this is the jail, saying that any IP number may make 30 hits in 60 seconds. If an IP number exceeds this (2s per page!) then it
gets blocked at the firewall for 10 minutes.</p>
<pre><code>[alex-apache]
enabled = true
port    = http,https
logpath = %(apache_access_log)s
findtime = 60
maxretry = 30
</code></pre>
<p>I also have another filter for a particular substring in URLs that I found the bots are requesting all the time:</p>
<pre><code>[Definition]
failregex = ^(www\\.emacswiki\\.org|communitywiki\\.org|campaignwiki\\.org):[0-9]+ <HOST> .*rcidonly=
</code></pre>
<p>The corresponding jail says that when you trigger request such a URL for the third time in an hour, you're blocked at the firewall for 10 minutes.</p>
<p>[alex-bots]
enabled = true
port    = http,https
logpath = %(apache_access_log)s
findtime = 3600
maxretry = 2</p>
<p>(At the same time, these URL's redirect to <a href=\"https://www.emacswiki.org/nobots\">a warning</a> so that humans know that this is a trap.)</p>
<p>Furthermore, <code>fail2ban</code> also comes with a <code>recidive</code> filter that watches its own logs. If an IP has been banned five times in a day, it gets banned for a week.</p>
<pre><code>[recidive]
enabled = true
</code></pre>
<p>To add to the <code>alex-bots</code> jail, here's what my Apache configuration says: RSS feeds for single pages are errors.</p>
<pre><code>RewriteCond %{QUERY_STRING} action=rss
RewriteCond %{QUERY_STRING} rcidonly=.*
RewriteRule .* /error.rss [last]
</code></pre>
<p>Note that all my sites also use the following headers, so anybody ignoring these is also a prime candidate for blocking.</p>
<pre><code># https://github.com/rom1504/img2dataset#opt-out-directives
Header always set X-Robots-Tag: noai
Header always set X-Robots-Tag: noimageai
</code></pre>
<p>All of the above still doesn't handle extremely distributed attacks. In such situations, almost all IP numbers are unique. What I try to do in this situation is block the entire IP range that they come from.
I scan the <code>access.log</code> for IP numbers that connected to a URL that shouldn't be used by bots because of <code>robots.txt</code>, containing <code>rcidonly</code> because I know humans will very rarely click it and it's expensive to serve. For each such IP number, I determine the IP range they come from, and then I block it all.</p>
<p>Basically, this is what I keep repeating:</p>
<pre><code># prefix with a timestamp
date
# log some candidates without whois information, skipping my fedi instance
tail -n 2000 /var/log/apache2/access.log \\
| grep -v ^social \\
| grep \"rcidonly\" \\
| bin/admin/network-lookup-lean > result.log
# count
grep ipset result.log|wc -l
# add
grep ipset result.log|sh
# document
grep ipset result.log>>bin/admin/ban-cidr
</code></pre>
<p>You can find the scripts in my <a href=\"https://alexschroeder.ch/admin/\">admin collection</a>.</p>
<p><a class=\"tag\" href=\"/search/?q=%23Administration\">#Administration</a> <a class=\"tag\" href=\"/search/?q=%23Butlerian_Jihad\">#Butlerian Jihad</a></p>
<p><strong>2025-03-22</strong>. The drawback of using the firewall to ban broad swaths of the Internet is that these networks host bots (bad) but also networked services that I'm interested in (good). Yesterday I found that <a class=\"account\" href=\"https://come-from.mad-scientist.club/@algernon\" title=\"@algernon@come-from.mad-scientist.club\">@algernon</a> had gone silent, had been silent for quite a while, and yet I kept seeing replies to them by others. Something was off. We got into contact via an alt account and indeed, I had blocked the IPv4 range his server was on.</p>
<p>So by my count I already had to unblock three networks on my list. It's not a great solution, to be honest.
And it doesn't expire, either. The list still contains 47021 IP ranges.</p>
" nil nil "7b9936984fa9ede0022a07ea022f3716") (15 (26591 55056 783191 463000) "https://alexschroeder.ch/view/2025-03-20-bot-defence" "2025-03-20 Something about the bot defence is working" nil "Sat, 22 Mar 2025 22:02:48 +0000" "<h1 id=\"2025-03-20-something-about-the-bot-defence-is-working\">2025-03-20 Something about the bot defence is working</h1>
<p>At midnight, there was a surge in activity.
CPU usage went up.</p>
<p><img loading=\"lazy\" src=\"2025-03-20-bot-defence-1.jpg\" alt=\"\" /></p>
<p>Load went up, too. But it stayed within reasonable bounds - less than 4 instead of the more than 80 I have seen in the past.</p>
<p><img loading=\"lazy\" src=\"2025-03-20-bot-defence-2.jpg\" alt=\"\" /></p>
<p>And the number of IP addresses blocked by <code>fail2ban</code> went from 40 to 50.</p>
<p><img loading=\"lazy\" src=\"2025-03-20-bot-defence-3.jpg\" alt=\"\" /></p>
<p>I'm usually sceptical of this because the big attacks are from a far wider variety of IP numbers.
In this case, however, maybe there was some probing that resulted in blocks? I don't know. Lucky, I guess?</p>
<p>In any case, the site is still up. Yay for small wins.</p>
<p>Also, I cannot overstate how good it feel to have some <a href=\"https://munin-monitoring.org/\">Munin</a> graphs available.</p>
<p><code>alex-bots</code> is a setup I desribed in <a href=\"2025-02-19-bots-again\">2025-02-19 Bots again, cursed</a>.
Basically a request to one of my Oddmuse wikis containing the parameter <code>rcidonly</code> is an expensive endpoint: ``all changes for this single page'' or ``a feed for this single page''. This is something a human would rarely access and yet it somehow the URLs landed in some dataset for AI training, I suspect. So what I do is I‚Äôm redirecting any request containing ‚Äúrcidonly‚Äù in the query string to <code>/nobots</code>, warning humans not to click on these links.</p>
<p>In addition to that, the filter <code>/etc/fail2ban/filter.d/alex-bots.conf</code> contains this:</p>
<pre><code>[Definition]
failregex = ^(www\\.emacswiki\\.org|communitywiki\\.org|campaignwiki\\.org):[0-9]+ <HOST> .*rcidonly=
</code></pre>
<p>And I added a section using this filter to my jail <code>/etc/fail2ban/jail.d/alex.conf</code>:</p>
<pre><code>[alex-bots]
enabled = true
port    = http,https
logpath = %(apache_access_log)s
findtime = 3600
maxretry = 2
</code></pre>
<p>So if an IP number visits three URLs containing ``rcidonly'' in an hour, they get banned for ten minutes.</p>
<p>The <code>recidive</code> filter (a standard filter you just need to activate) then makes sure that any IP number that got blocked three times gets blocked for a week.</p>
<p><a class=\"tag\" href=\"/search/?q=%23Administration\">#Administration</a> <a class=\"tag\" href=\"/search/?q=%23Butlerian_Jihad\">#Butlerian Jihad</a></p>
<p><strong>2025-03-20</strong>. Ever since Drew DeVault published his blog post, more people seem to notice what's going on: AI ingestion is killing web sites and web services.</p>
<blockquote>
<p>If you think these crawlers respect <code>robots.txt</code> then you are several assumptions of good faith removed from reality. These bots crawl everything they can find, <code>robots.txt</code> be damned, including expensive endpoints like git blame, every page of every git log, and every commit in every repo, and they do so using random User-Agents that overlap with end-users and come from tens of thousands of IP addresses ‚Äì mostly residential, in unrelated subnets, each one making no more than one HTTP request over any time period we tried to measure ‚Äì actively and maliciously adapting and blending in with end-user traffic and avoiding attempts to characterize their behavior or block their traffic. - <a href=\"https://drewdevault.com/2025/03/17/2025-03-17-Stop-externalizing-your-costs-on-me.html\">Please stop externalizing your costs directly into my face</a>, by Drew DeVault, for SourceHut</p>
<p>Then, yesterday morning, KDE GitLab infrastructure was overwhelmed by another AI crawler, with IPs from an Alibaba range; this caused GitLab to be temporarily inaccessible by KDE developers. I then discovered that, one week ago, an Anime girl started appearing on the GNOME GitLab instance, as the page was loaded. It turns out that it's the default loading page for Anubis, a proof-of-work challenger that blocks AI scrapers that are causing outages. - <a href=\"https://thelibre.news/foss-infrastructure-is-under-attack-by-ai-companies/\">FOSS infrastructure is under attack by AI companies</a>, by Niccol√≤ Venerandi, for LibreNews</p>
<p>What do SourceHut, GNOME‚Äôs GitLab, and KDE‚Äôs GitLab have in common, other than all three of them being forges? Well, it turns out all three of them have been dealing with immense amounts of traffic from ‚ÄúAI‚Äù scrapers, who are effectively performing DDoS attacks with such ferocity it‚Äôs bringing down the infrastructures of these major open source projects. Being open source, and thus publicly accessible, means these scrapers have unlimited access, unlike with proprietary projects. ‚Ä¶ Everything about this ‚ÄúAI‚Äù bubble is gross, and I can‚Äôt wait for this bubble to pop so a semblance of sanity can return to the technology world. Until the next hype train rolls into the station, of course. - <a href=\"https://www.osnews.com/story/141969/foss-infrastructure-is-under-attack-by-ai-companies/\">FOSS infrastructure is under attack by AI companies</a>, by Thom Holwerda, for OSnews</p>
</blockquote>
<p><strong>2025-03-22</strong>. Ordinary sysadmins get hit as well. Here's Sean Conner of the The Boston Diaries: He reports on <a href=\"https://boston.conman.org/2025/03/21\">Friday, March 21, 2025</a> that his logs show a total of 468439 requests for February 2025. The top hitter was 4.231.104.62 with 43242 requests (9%). This was from MICROSOFT-CORP-MSN-AS-BLOCK, US. But the ASN has more networks, of course. Adding them all up give 78889 (17%).</p>
<p>He links to the <a href=\"https://www.team-cymru.com/ip-asn-mapping\">IP to ASN Mapping Service</a> by Team Cymru. Apparently, this is also used by the Perl library <code>Net::Abuse::Utils</code>. I should use it!</p>
" nil nil "ad75dba75171feb6b8dabae3cca1a5de") (14 (26590 50399 782366 374000) "https://alexschroeder.ch/view/2025-03-21-defence-summary" "2025-03-21 A summary of my bot defence systems" nil "Sat, 22 Mar 2025 12:03:34 +0000" "<h1 id=\"2025-03-21-a-summary-of-my-bot-defence-systems\">2025-03-21 A summary of my bot defence systems</h1>
<p>If you've followed my <a href=\"Butlerian_Jihad\">Butlerian Jihad</a> pages, you know that I'm constantly fiddling with the setup.
Each page got written in the middle of an attack as I'm trying to save my sites, documenting as I go along. But if
you're looking for an overview, there is nothing to see. It's all over the place. Since the topic has gained some
traction in recent days, I'm going to assemble all the things I do on this page.</p>
<p>Here's Drew DeVault complaining about the problem that system administrators have been facing for a while, now:</p>
<blockquote>
<p>If you think these crawlers respect <code>robots.txt</code> then you are several assumptions of good faith removed from reality. These bots crawl everything they can find, <code>robots.txt</code> be damned, including expensive endpoints like git blame, every page of every git log, and every commit in every repo, and they do so using random User-Agents that overlap with end-users and come from tens of thousands of IP addresses ‚Äì mostly residential, in unrelated subnets, each one making no more than one HTTP request over any time period we tried to measure ‚Äì actively and maliciously adapting and blending in with end-user traffic and avoiding attempts to characterize their behavior or block their traffic. - <a href=\"https://drewdevault.com/2025/03/17/2025-03-17-Stop-externalizing-your-costs-on-me.html\">Please stop externalizing your costs directly into my face</a>, by Drew DeVault, for SourceHut</p>
</blockquote>
<p>I had read some similar reports before, on fedi, but this one links to quite a few of them: <a href=\"https://thelibre.news/foss-infrastructure-is-under-attack-by-ai-companies/\">FOSS infrastructure is under attack by AI companies</a>, by Niccol√≤ Venerandi, for LibreNews.</p>
<p>I'm going to skip the defences against spam as spam hasn't been a problem in recent months, surprisingly.</p>
<p>The first defence against bots is <code>robots.txt</code>. All well-behaving bots should read it every now and then and then either stop crawling
the site or slow down.</p>
<p>Let's look at the file <a href=\"https://www.emacswiki.org/robots.txt\">for Emacs Wiki</a>.</p>
<p>If I find that there are lot of requests from a particular user agent that looks like bot, and it has a URL where I can find instructions
for how to address it in <code>robots.txt</code>, this is what I do. I tell them to stop crawling the entire site. Most of these are search engine optimizers, brand awareness monitors and other such creeps.</p>
<p>The file also tells all well-behaving crawlers to slow down to a glacial tempo and it lists all the expensive endpoints that they should not be crawling at all. Conversely, this means that any bot that still crawls those URLs is a misbehaving bot and deserves to be blocked.</p>
<p>Worth noting, perhaps, that ``an expensive endpoint'' means a URL that runs some executable to do something complicated, resulting in an answer that's always different. If the URL causes the web server to run a CGI script, for example, the request loads Perl, loads a script, loads all its libraries, compiles it all, runs it once, and answers with the request with the output. And since the answer is dynamic, it can't very well be cached, or additional complexity needs to be introduced and even more resources need to be allocated and paid for. In short, an expensive end-point is like loading an app. It's slow but useful, if done rarely. So you'd do this for a human, for example. It's a disaster if bots swarm all over the site, clicking on every link.</p>
<p>It's also worth noting that not all my sites have the same expensive endpoints and so the second half of <code>robots.txt</code> can vary. Which makes maintenance of the first half a chore. I have a little script that allows me to add one bot to ``all'' the files, but it's annoying to have to do that. And I recently just copied a list from an <a href=\"https://robotstxt.com/ai\">AI / LLM User-Agents: Blocking Guide</a>.</p>
<p>I use Apache as my web-server and I have a bunch of global configuration files to handle misbehaving bots and crawlers.</p>
<p>This example blocks fediverse agents from accessing my site. That's because whenever anybody post a URL to one of my sites, within the next
60 seconds, all the servers with users getting a copy of the URL will fetch a preview. That means hundreds of hits. This is particularly
obnoxious for expensive endpoints. This response here tells them that they are forbidden from accessing the page.</p>
<pre><code># Fediverse instances asking for previews: protect the expensive endpoints
RewriteCond %{REQUEST_URI} /(wiki|download|food|paper|hug|helmut|input|korero|check|radicale|say|mojo|software)
RewriteCond %{HTTP_USER_AGENT} Mastodon|Friendica|Pleroma [nocase]
# then it's forbidden
RewriteRule ^(.*)$ - [forbidden,last]
</code></pre>
<p>These are the evil bots that self-identify as a bot but don't seem to heed the <code>robots.txt</code> files. These are all told that whatever page they were looking for, it's now gone (410). And if there's a human looking at the output, it even links to an explanation. Adding new user agents to this list is annoying because I need to connect as root and restart the web server after making any changes.</p>
<pre><code># SEO bots, borked feed services and other shit
RewriteCond \"%{HTTP_USER_AGENT}\" \"academicbotrtu|ahrefsbot|amazonbot|awariobot|bitsightbot|blexbot|bytespider|dataforseobot|discordbot|domainstatsbot|dotbot|elisabot|eyemonit|facebot|linkfluence|magpie-crawler|megaindex|mediatoolkitbot|mj12bot|newslitbot|paperlibot|pcore|petalbot|pinterestbot|seekportbot|semanticscholarbot|semrushbot|semanticbot|seokicks-robot|siteauditbot|startmebot|summalybot|synapse|trendictionbot|twitterbot|wiederfrei|yandexbot|zoominfobot|velenpublicwebcrawler|gpt|\\bads|feedburner|brandwatch|openai|facebookexternalhit|yisou|docspider\" [nocase]
RewriteRule ^ https://alexschroeder.ch/nobots [redirect=410,last]
</code></pre>
<p>For some of my sites, I disallow all user agents containing the words ``bot'', ``crawler'', ``spider'', ``ggpht'' or ``gpt'' with the exception of ``archivebot'' and ``wibybot'' because these two bots I want to give access. Again, these bots are all told that whatever page they were looking for, it's now gone (410).</p>
<pre><code># Private sites block all bots and crawlers. This list does no include
# social.alexschroeder.ch, communitywiki.org, www.emacswiki.org,
# oddmuse.org, orientalisch.info, korero.org.
RewriteCond \"%{HTTP_HOST}\" \"^((src\\.)?alexschroeder\\.ch|flying-carpet\\.ch|next\\.oddmuse\\.org|((chat|talk)\\.)?campaignwiki\\.org|((archive|vault|toki|xn--vxagggm5c)\\.)?transjovian\\.org)$\" [nocase]
RewriteCond \"%{HTTP_USER_AGENT}\" \"!archivebot|^gwene|wibybot\" [nocase]
RewriteCond \"%{HTTP_USER_AGENT}\" \"bot|crawler|spider|ggpht|gpt\" [nocase]
RewriteRule ^ https://alexschroeder.ch/nobots [redirect=410,last]
</code></pre>
<p>I also eliminate a lot of bots looking for PHP endpoints. I can do this because I know that I don't have any PHP application installed.</p>
<pre><code># Deny all idiots that are looking for borked PHP applications
RewriteRule \\.php$ https://alexschroeder.ch/nobots [redirect=410,last]
</code></pre>
<p>There's also one particular image scraper that's using a unique string in its user agent.</p>
<pre><code># Deny the image scraper
# https://imho.alex-kunz.com/2024/02/25/block-this-shit/
RewriteCond \"%{HTTP_USER_AGENT}\" \"Firefox/72.0\" [nocase]
RewriteRule ^ https://alexschroeder.ch/nobots [redirect=410,last]
</code></pre>
<p>Next, all requests get logged by Apache in the <code>access.log</code> file. I use <code>fail2ban</code> to check this logfile. This is somewhat interesting
because <code>fail2ban</code> is usually used to check for failed ssh login attempts. Those IP numbers that fail to login in a few times are banned.
What I'm doing is I wrote a filter that treats every hit on the web server as a ``failed login attempt''.</p>
<p>This is the filter:</p>
<pre><code>[Definition]
# Most sites in the logfile count! What doesn't count is fedi.alexschroeder.ch, or chat.campaignwiki.org.
failregex = ^(www\\.)?(alexschroeder\\.ch|campaignwiki\\.org|communitywiki\\.org|emacswiki\\.org|flying-carpet\\.ch|korero\\.org|oddmuse\\.org|orientalisch\\.info):[0-9]+ <HOST>
# Except css files, images...
ignoreregex = ^[^\"]*\"(GET /(robots\\.txt |favicon\\.ico |[^/ \\\"]+\\.(css|js) |[^\\\"]*\\.(jpg|JPG|png|PNG) |css/|fonts/|pdfs/|txt/|pics/|export/|podcast/|1pdc/|static/|munin/|osr/|indie/|rpg/|face/|traveller/|hex-describe/|text-mapper/|contrib/pics/|roll/|alrik/|wiki/download/)|(OPTIONS|PROPFIND|REPORT) /radicale)
</code></pre>
<p>And this is the jail, saying that any IP number may make 30 hits in 60 seconds. If an IP number exceeds this (2s per page!) then it
gets blocked at the firewall for 10 minutes.</p>
<pre><code>[alex-apache]
enabled = true
port    = http,https
logpath = %(apache_access_log)s
findtime = 60
maxretry = 30
</code></pre>
<p>I also have another filter for a particular substring in URLs that I found the bots are requesting all the time:</p>
<pre><code>[Definition]
failregex = ^(www\\.emacswiki\\.org|communitywiki\\.org|campaignwiki\\.org):[0-9]+ <HOST> .*rcidonly=
</code></pre>
<p>The corresponding jail says that when you trigger request such a URL for the third time in an hour, you're blocked at the firewall for 10 minutes.</p>
<p>[alex-bots]
enabled = true
port    = http,https
logpath = %(apache_access_log)s
findtime = 3600
maxretry = 2</p>
<p>(At the same time, these URL's redirect to <a href=\"https://www.emacswiki.org/nobots\">a warning</a> so that humans know that this is a trap.)</p>
<p>Furthermore, <code>fail2ban</code> also comes with a <code>recidive</code> filter that watches its own logs. If an IP has been banned five times in a day, it gets banned for a week.</p>
<pre><code>[recidive]
enabled = true
</code></pre>
<p>To add to the <code>alex-bots</code> jail, here's what my Apache configuration says: RSS feeds for single pages are errors.</p>
<pre><code>RewriteCond %{QUERY_STRING} action=rss
RewriteCond %{QUERY_STRING} rcidonly=.*
RewriteRule .* /error.rss [last]
</code></pre>
<p>Note that all my sites also use the following headers, so anybody ignoring these is also a prime candidate for blocking.</p>
<pre><code># https://github.com/rom1504/img2dataset#opt-out-directives
Header always set X-Robots-Tag: noai
Header always set X-Robots-Tag: noimageai
</code></pre>
<p>All of the above still doesn't handle extremely distributed attacks. In such situations, almost all IP numbers are unique. What I try to do in this situation is block the entire IP range that they come from.
I scan the <code>access.log</code> for IP numbers that connected to a URL that shouldn't be used by bots because of <code>robots.txt</code>, containing <code>rcidonly</code> because I know humans will very rarely click it and it's expensive to serve. For each such IP number, I determine the IP range they come from, and then I block it all.</p>
<p>Basically, this is what I keep repeating:</p>
<pre><code># prefix with a timestamp
date
# log some candidates without whois information, skipping my fedi instance
tail -n 2000 /var/log/apache2/access.log \\
| grep -v ^social \\
| grep \"rcidonly\" \\
| bin/admin/network-lookup-lean > result.log
# count
grep ipset result.log|wc -l
# add
grep ipset result.log|sh
# document
grep ipset result.log>>bin/admin/ban-cidr
</code></pre>
<p>You can find the scripts in my <a href=\"https://alexschroeder.ch/admin/\">admin collection</a>.</p>
<p><a class=\"tag\" href=\"/search/?q=%23Administration\">#Administration</a> <a class=\"tag\" href=\"/search/?q=%23Butlerian_Jihad\">#Butlerian Jihad</a></p>
<p><strong>2025-03-22</strong>. The drawback of using the firewall to ban broad swaths of the Internet is that these networks host bots (bad) but also networked services that I'm interested in (good). Yesterday I found that <a class=\"account\" href=\"https://come-from.mad-scientist.club/users/algernon\" title=\"@algernon@come-from.mad-scientist.club\">@algernon</a> had gone silent, had been silent for quite a while, and yet I kept seeing replies to them by others. Something was off. We got into contact via an alt account and indeed, I had blocked the IPv4 range his server was on.</p>
<p>So by my count I already had to unblock three networks on my list. It's not a great solution, to be honest.
And it doesn't expire, either. The list still contains 47021 IP ranges.</p>
" nil nil "4c3c87f4fe579064731b9b0ceb60c4a9") (13 (26590 33237 863861 78000) "https://alexschroeder.ch/view/2025-03-21-defence-summary" "2025-03-21 A summary of my bot defence systems" nil "Fri, 21 Mar 2025 15:28:52 +0000" "<h1 id=\"2025-03-21-a-summary-of-my-bot-defence-systems\">2025-03-21 A summary of my bot defence systems</h1>
<p>If you've followed my <a href=\"Butlerian_Jihad\">Butlerian Jihad</a> pages, you know that I'm constantly fiddling with the setup.
Each page got written in the middle of an attack as I'm trying to save my sites, documenting as I go along. But if
you're looking for an overview, there is nothing to see. It's all over the place. Since the topic has gained some
traction in recent days, I'm going to assemble all the things I do on this page.</p>
<p>Here's Drew DeVault complaining about the problem that system administrators have been facing for a while, now:</p>
<blockquote>
<p>If you think these crawlers respect <code>robots.txt</code> then you are several assumptions of good faith removed from reality. These bots crawl everything they can find, <code>robots.txt</code> be damned, including expensive endpoints like git blame, every page of every git log, and every commit in every repo, and they do so using random User-Agents that overlap with end-users and come from tens of thousands of IP addresses ‚Äì mostly residential, in unrelated subnets, each one making no more than one HTTP request over any time period we tried to measure ‚Äì actively and maliciously adapting and blending in with end-user traffic and avoiding attempts to characterize their behavior or block their traffic. - <a href=\"https://drewdevault.com/2025/03/17/2025-03-17-Stop-externalizing-your-costs-on-me.html\">Please stop externalizing your costs directly into my face</a>, by Drew DeVault, for SourceHut</p>
</blockquote>
<p>I had read some similar reports before, on fedi, but this one links to quite a few of them: <a href=\"https://thelibre.news/foss-infrastructure-is-under-attack-by-ai-companies/\">FOSS infrastructure is under attack by AI companies</a>, by Niccol√≤ Venerandi, for LibreNews.</p>
<p>I'm going to skip the defences against spam as spam hasn't been a problem in recent months, surprisingly.</p>
<p>The first defence against bots is <code>robots.txt</code>. All well-behaving bots should read it every now and then and then either stop crawling
the site or slow down.</p>
<p>Let's look at the file <a href=\"https://www.emacswiki.org/robots.txt\">for Emacs Wiki</a>.</p>
<p>If I find that there are lot of requests from a particular user agent that looks like bot, and it has a URL where I can find instructions
for how to address it in <code>robots.txt</code>, this is what I do. I tell them to stop crawling the entire site. Most of these are search engine optimizers, brand awareness monitors and other such creeps.</p>
<p>The file also tells all well-behaving crawlers to slow down to a glacial tempo and it lists all the expensive endpoints that they should not be crawling at all. Conversely, this means that any bot that still crawls those URLs is a misbehaving bot and deserves to be blocked.</p>
<p>Worth noting, perhaps, that ``an expensive endpoint'' means a URL that runs some executable to do something complicated, resulting in an answer that's always different. If the URL causes the web server to run a CGI script, for example, the request loads Perl, loads a script, loads all its libraries, compiles it all, runs it once, and answers with the request with the output. And since the answer is dynamic, it can't very well be cached, or additional complexity needs to be introduced and even more resources need to be allocated and paid for. In short, an expensive end-point is like loading an app. It's slow but useful, if done rarely. So you'd do this for a human, for example. It's a disaster if bots swarm all over the site, clicking on every link.</p>
<p>It's also worth noting that not all my sites have the same expensive endpoints and so the second half of <code>robots.txt</code> can vary. Which makes maintenance of the first half a chore. I have a little script that allows me to add one bot to ``all'' the files, but it's annoying to have to do that. And I recently just copied a list from an <a href=\"https://robotstxt.com/ai\">AI / LLM User-Agents: Blocking Guide</a>.</p>
<p>I use Apache as my web-server and I have a bunch of global configuration files to handle misbehaving bots and crawlers.</p>
<p>This example blocks fediverse agents from accessing my site. That's because whenever anybody post a URL to one of my sites, within the next
60 seconds, all the servers with users getting a copy of the URL will fetch a preview. That means hundreds of hits. This is particularly
obnoxious for expensive endpoints. This response here tells them that they are forbidden from accessing the page.</p>
<pre><code># Fediverse instances asking for previews: protect the expensive endpoints
RewriteCond %{REQUEST_URI} /(wiki|download|food|paper|hug|helmut|input|korero|check|radicale|say|mojo|software)
RewriteCond %{HTTP_USER_AGENT} Mastodon|Friendica|Pleroma [nocase]
# then it's forbidden
RewriteRule ^(.*)$ - [forbidden,last]
</code></pre>
<p>These are the evil bots that self-identify as a bot but don't seem to heed the <code>robots.txt</code> files. These are all told that whatever page they were looking for, it's now gone (410). And if there's a human looking at the output, it even links to an explanation. Adding new user agents to this list is annoying because I need to connect as root and restart the web server after making any changes.</p>
<pre><code># SEO bots, borked feed services and other shit
RewriteCond \"%{HTTP_USER_AGENT}\" \"academicbotrtu|ahrefsbot|amazonbot|awariobot|bitsightbot|blexbot|bytespider|dataforseobot|discordbot|domainstatsbot|dotbot|elisabot|eyemonit|facebot|linkfluence|magpie-crawler|megaindex|mediatoolkitbot|mj12bot|newslitbot|paperlibot|pcore|petalbot|pinterestbot|seekportbot|semanticscholarbot|semrushbot|semanticbot|seokicks-robot|siteauditbot|startmebot|summalybot|synapse|trendictionbot|twitterbot|wiederfrei|yandexbot|zoominfobot|velenpublicwebcrawler|gpt|\\bads|feedburner|brandwatch|openai|facebookexternalhit|yisou|docspider\" [nocase]
RewriteRule ^ https://alexschroeder.ch/nobots [redirect=410,last]
</code></pre>
<p>For some of my sites, I disallow all user agents containing the words ``bot'', ``crawler'', ``spider'', ``ggpht'' or ``gpt'' with the exception of ``archivebot'' and ``wibybot'' because these two bots I want to give access. Again, these bots are all told that whatever page they were looking for, it's now gone (410).</p>
<pre><code># Private sites block all bots and crawlers. This list does no include
# social.alexschroeder.ch, communitywiki.org, www.emacswiki.org,
# oddmuse.org, orientalisch.info, korero.org.
RewriteCond \"%{HTTP_HOST}\" \"^((src\\.)?alexschroeder\\.ch|flying-carpet\\.ch|next\\.oddmuse\\.org|((chat|talk)\\.)?campaignwiki\\.org|((archive|vault|toki|xn--vxagggm5c)\\.)?transjovian\\.org)$\" [nocase]
RewriteCond \"%{HTTP_USER_AGENT}\" \"!archivebot|^gwene|wibybot\" [nocase]
RewriteCond \"%{HTTP_USER_AGENT}\" \"bot|crawler|spider|ggpht|gpt\" [nocase]
RewriteRule ^ https://alexschroeder.ch/nobots [redirect=410,last]
</code></pre>
<p>I also eliminate a lot of bots looking for PHP endpoints. I can do this because I know that I don't have any PHP application installed.</p>
<pre><code># Deny all idiots that are looking for borked PHP applications
RewriteRule \\.php$ https://alexschroeder.ch/nobots [redirect=410,last]
</code></pre>
<p>There's also one particular image scraper that's using a unique string in its user agent.</p>
<pre><code># Deny the image scraper
# https://imho.alex-kunz.com/2024/02/25/block-this-shit/
RewriteCond \"%{HTTP_USER_AGENT}\" \"Firefox/72.0\" [nocase]
RewriteRule ^ https://alexschroeder.ch/nobots [redirect=410,last]
</code></pre>
<p>Next, all requests get logged by Apache in the <code>access.log</code> file. I use <code>fail2ban</code> to check this logfile. This is somewhat interesting
because <code>fail2ban</code> is usually used to check for failed ssh login attempts. Those IP numbers that fail to login in a few times are banned.
What I'm doing is I wrote a filter that treats every hit on the web server as a ``failed login attempt''.</p>
<p>This is the filter:</p>
<pre><code>[Definition]
# Most sites in the logfile count! What doesn't count is fedi.alexschroeder.ch, or chat.campaignwiki.org.
failregex = ^(www\\.)?(alexschroeder\\.ch|campaignwiki\\.org|communitywiki\\.org|emacswiki\\.org|flying-carpet\\.ch|korero\\.org|oddmuse\\.org|orientalisch\\.info):[0-9]+ <HOST>
# Except css files, images...
ignoreregex = ^[^\"]*\"(GET /(robots\\.txt |favicon\\.ico |[^/ \\\"]+\\.(css|js) |[^\\\"]*\\.(jpg|JPG|png|PNG) |css/|fonts/|pdfs/|txt/|pics/|export/|podcast/|1pdc/|static/|munin/|osr/|indie/|rpg/|face/|traveller/|hex-describe/|text-mapper/|contrib/pics/|roll/|alrik/|wiki/download/)|(OPTIONS|PROPFIND|REPORT) /radicale)
</code></pre>
<p>And this is the jail, saying that any IP number may make 30 hits in 60 seconds. If an IP number exceeds this (2s per page!) then it
gets blocked at the firewall for 10 minutes.</p>
<pre><code>[alex-apache]
enabled = true
port    = http,https
logpath = %(apache_access_log)s
findtime = 60
maxretry = 30
</code></pre>
<p>I also have another filter for a particular substring in URLs that I found the bots are requesting all the time:</p>
<pre><code>[Definition]
failregex = ^(www\\.emacswiki\\.org|communitywiki\\.org|campaignwiki\\.org):[0-9]+ <HOST> .*rcidonly=
</code></pre>
<p>The corresponding jail says that when you trigger request such a URL for the third time in an hour, you're blocked at the firewall for 10 minutes.</p>
<p>[alex-bots]
enabled = true
port    = http,https
logpath = %(apache_access_log)s
findtime = 3600
maxretry = 2</p>
<p>(At the same time, these URL's redirect to <a href=\"https://www.emacswiki.org/nobots\">a warning</a> so that humans know that this is a trap.)</p>
<p>Furthermore, <code>fail2ban</code> also comes with a <code>recidive</code> filter that watches its own logs. If an IP has been banned five times in a day, it gets banned for a week.</p>
<pre><code>[recidive]
enabled = true
</code></pre>
<p>To add to the <code>alex-bots</code> jail, here's what my Apache configuration says: RSS feeds for single pages are errors.</p>
<pre><code>RewriteCond %{QUERY_STRING} action=rss
RewriteCond %{QUERY_STRING} rcidonly=.*
RewriteRule .* /error.rss [last]
</code></pre>
<p>Note that all my sites also use the following headers, so anybody ignoring these is also a prime candidate for blocking.</p>
<pre><code># https://github.com/rom1504/img2dataset#opt-out-directives
Header always set X-Robots-Tag: noai
Header always set X-Robots-Tag: noimageai
</code></pre>
<p>All of the above still doesn't handle extremely distributed attacks. In such situations, almost all IP numbers are unique. What I try to do in this situation is block the entire IP range that they come from.
I scan the <code>access.log</code> for IP numbers that connected to a URL that shouldn't be used by bots because of <code>robots.txt</code>, containing <code>rcidonly</code> because I know humans will very rarely click it and it's expensive to serve. For each such IP number, I determine the IP range they come from, and then I block it all.</p>
<p>Basically, this is what I keep repeating:</p>
<pre><code># prefix with a timestamp
date
# log some candidates without whois information, skipping my fedi instance
tail -n 2000 /var/log/apache2/access.log \\
| grep -v ^social \\
| grep \"rcidonly\" \\
| bin/admin/network-lookup-lean > result.log
# count
grep ipset result.log|wc -l
# add
grep ipset result.log|sh
# document
grep ipset result.log>>bin/admin/ban-cidr
</code></pre>
<p>You can find the scripts in my <a href=\"https://alexschroeder.ch/admin/\">admin collection</a>.</p>
<p><a class=\"tag\" href=\"/search/?q=%23Administration\">#Administration</a> <a class=\"tag\" href=\"/search/?q=%23Butlerian_Jihad\">#Butlerian Jihad</a></p>
" nil nil "4702b888bfc3a8b70c574cb7e58caa5a") (12 (26590 33237 863104 875000) "https://alexschroeder.ch/view/2025-03-20-bot-defence" "2025-03-20 Something about the bot defence is working" nil "Fri, 21 Mar 2025 14:59:24 +0000" "<h1 id=\"2025-03-20-something-about-the-bot-defence-is-working\">2025-03-20 Something about the bot defence is working</h1>
<p>At midnight, there was a surge in activity.
CPU usage went up.</p>
<p><img loading=\"lazy\" src=\"2025-03-20-bot-defence-1.jpg\" alt=\"\" /></p>
<p>Load went up, too. But it stayed within reasonable bounds - less than 4 instead of the more than 80 I have seen in the past.</p>
<p><img loading=\"lazy\" src=\"2025-03-20-bot-defence-2.jpg\" alt=\"\" /></p>
<p>And the number of IP addresses blocked by <code>fail2ban</code> went from 40 to 50.</p>
<p><img loading=\"lazy\" src=\"2025-03-20-bot-defence-3.jpg\" alt=\"\" /></p>
<p>I'm usually sceptical of this because the big attacks are from a far wider variety of IP numbers.
In this case, however, maybe there was some probing that resulted in blocks? I don't know. Lucky, I guess?</p>
<p>In any case, the site is still up. Yay for small wins.</p>
<p>Also, I cannot overstate how good it feel to have some <a href=\"https://munin-monitoring.org/\">Munin</a> graphs available.</p>
<p><code>alex-bots</code> is a setup I desribed in <a href=\"2025-02-19-bots-again\">2025-02-19 Bots again, cursed</a>.
Basically a request to one of my Oddmuse wikis containing the parameter <code>rcidonly</code> is an expensive endpoint: ``all changes for this single page'' or ``a feed for this single page''. This is something a human would rarely access and yet it somehow the URLs landed in some dataset for AI training, I suspect. So what I do is I‚Äôm redirecting any request containing ‚Äúrcidonly‚Äù in the query string to <code>/nobots</code>, warning humans not to click on these links.</p>
<p>In addition to that, the filter <code>/etc/fail2ban/filter.d/alex-bots.conf</code> contains this:</p>
<pre><code>[Definition]
failregex = ^(www\\.emacswiki\\.org|communitywiki\\.org|campaignwiki\\.org):[0-9]+ <HOST> .*rcidonly=
</code></pre>
<p>And I added a section using this filter to my jail <code>/etc/fail2ban/jail.d/alex.conf</code>:</p>
<pre><code>[alex-bots]
enabled = true
port    = http,https
logpath = %(apache_access_log)s
findtime = 3600
maxretry = 2
</code></pre>
<p>So if an IP number visits three URLs containing ``rcidonly'' in an hour, they get banned for ten minutes.</p>
<p>The <code>recidive</code> filter (a standard filter you just need to activate) then makes sure that any IP number that got blocked three times gets blocked for a week.</p>
<p><a class=\"tag\" href=\"/search/?q=%23Administration\">#Administration</a> <a class=\"tag\" href=\"/search/?q=%23Butlerian_Jihad\">#Butlerian Jihad</a></p>
<p><strong>2025-03-20</strong>. Ever since Drew DeVault published his blog post, more people seem to notice what's going on: AI ingestion is killing web sites and web services.</p>
<blockquote>
<p>If you think these crawlers respect <code>robots.txt</code> then you are several assumptions of good faith removed from reality. These bots crawl everything they can find, <code>robots.txt</code> be damned, including expensive endpoints like git blame, every page of every git log, and every commit in every repo, and they do so using random User-Agents that overlap with end-users and come from tens of thousands of IP addresses ‚Äì mostly residential, in unrelated subnets, each one making no more than one HTTP request over any time period we tried to measure ‚Äì actively and maliciously adapting and blending in with end-user traffic and avoiding attempts to characterize their behavior or block their traffic. - <a href=\"https://drewdevault.com/2025/03/17/2025-03-17-Stop-externalizing-your-costs-on-me.html\">Please stop externalizing your costs directly into my face</a>, by Drew DeVault, for SourceHut</p>
<p>Then, yesterday morning, KDE GitLab infrastructure was overwhelmed by another AI crawler, with IPs from an Alibaba range; this caused GitLab to be temporarily inaccessible by KDE developers. I then discovered that, one week ago, an Anime girl started appearing on the GNOME GitLab instance, as the page was loaded. It turns out that it's the default loading page for Anubis, a proof-of-work challenger that blocks AI scrapers that are causing outages. - <a href=\"https://thelibre.news/foss-infrastructure-is-under-attack-by-ai-companies/\">FOSS infrastructure is under attack by AI companies</a>, by Niccol√≤ Venerandi, for LibreNews</p>
<p>What do SourceHut, GNOME‚Äôs GitLab, and KDE‚Äôs GitLab have in common, other than all three of them being forges? Well, it turns out all three of them have been dealing with immense amounts of traffic from ‚ÄúAI‚Äù scrapers, who are effectively performing DDoS attacks with such ferocity it‚Äôs bringing down the infrastructures of these major open source projects. Being open source, and thus publicly accessible, means these scrapers have unlimited access, unlike with proprietary projects. ‚Ä¶ Everything about this ‚ÄúAI‚Äù bubble is gross, and I can‚Äôt wait for this bubble to pop so a semblance of sanity can return to the technology world. Until the next hype train rolls into the station, of course. - <a href=\"https://www.osnews.com/story/141969/foss-infrastructure-is-under-attack-by-ai-companies/\">FOSS infrastructure is under attack by AI companies</a>, by Thom Holwerda, for OSnews</p>
</blockquote>
" nil nil "7dff2c89697a86d81d1afa85ee637f85") (11 (26588 11780 102477 30000) "https://alexschroeder.ch/view/2025-03-20-bot-defence" "2025-03-20 Something about the bot defence is working" nil "Thu, 20 Mar 2025 16:00:10 +0000" "<h1 id=\"2025-03-20-something-about-the-bot-defence-is-working\">2025-03-20 Something about the bot defence is working</h1>
<p>At midnight, there was a surge in activity.
CPU usage went up.</p>
<p><img loading=\"lazy\" src=\"2025-03-20-bot-defence-1.jpg\" alt=\"\" /></p>
<p>Load went up, too. But it stayed within reasonable bounds - less than 4 instead of the more than 80 I have seen in the past.</p>
<p><img loading=\"lazy\" src=\"2025-03-20-bot-defence-2.jpg\" alt=\"\" /></p>
<p>And the number of IP addresses blocked by <code>fail2ban</code> went from 40 to 50.</p>
<p><img loading=\"lazy\" src=\"2025-03-20-bot-defence-3.jpg\" alt=\"\" /></p>
<p>I'm usually sceptical of this because the big attacks are from a far wider variety of IP numbers.
In this case, however, maybe there was some probing that resulted in blocks? I don't know. Lucky, I guess?</p>
<p>In any case, the site is still up. Yay for small wins.</p>
<p>Also, I cannot overstate how good it feel to have some <a href=\"https://munin-monitoring.org/\">Munin</a> graphs available.</p>
<p><code>alex-bots</code> is a setup I desribed in <a href=\"2025-02-19-bots-again\">2025-02-19 Bots again, cursed</a>.
Basically a request to one of my Oddmuse wikis containing the parameter <code>rcidonly</code> is an expensive endpoint: ``all changes for this single page'' or ``a feed for this single page''. This is something a human would rarely access and yet it somehow the URLs landed in some dataset for AI training, I suspect. So what I do is I‚Äôm redirecting any request containing ‚Äúrcidonly‚Äù in the query string to <code>/nobots</code>, warning humans not to click on these links.</p>
<p>In addition to that, the filter <code>/etc/fail2ban/filter.d/alex-bots.conf</code> contains this:</p>
<pre><code>[Definition]
failregex = ^(www\\.emacswiki\\.org|communitywiki\\.org|campaignwiki\\.org):[0-9]+ <HOST> .*rcidonly=
</code></pre>
<p>And I added a section using this filter to my jail <code>/etc/fail2ban/jail.d/alex.conf</code>:</p>
<pre><code>[alex-bots]
enabled = true
port    = http,https
logpath = %(apache_access_log)s
findtime = 3600
maxretry = 2
</code></pre>
<p>So if an IP number visits three URLs containing ``rcidonly'' in an hour, they get banned for ten minutes.</p>
<p>The <code>recidive</code> filter (a standard filter you just need to activate) then makes sure that any IP number that got blocked three times gets blocked for a week.</p>
<p><a class=\"tag\" href=\"/search/?q=%23Administration\">#Administration</a> <a class=\"tag\" href=\"/search/?q=%23Butlerian_Jihad\">#Butlerian Jihad</a></p>
<p><strong>2025-03-20</strong>. Ever since Drew DeVault published his blog post, more people seem to notice what's going on: AI ingestion is killing web sites and web services.</p>
<blockquote>
<p>If you think these crawlers respect <code>robots.txt</code> then you are several assumptions of good faith removed from reality. These bots crawl everything they can find, <code>robots.txt</code> be damned, including expensive endpoints like git blame, every page of every git log, and every commit in every repo, and they do so using random User-Agents that overlap with end-users and come from tens of thousands of IP addresses ‚Äì mostly residential, in unrelated subnets, each one making no more than one HTTP request over any time period we tried to measure ‚Äì actively and maliciously adapting and blending in with end-user traffic and avoiding attempts to characterize their behavior or block their traffic. - <a href=\"https://drewdevault.com/2025/03/17/2025-03-17-Stop-externalizing-your-costs-on-me.html\">Please stop externalizing your costs directly into my face</a>, by Drew DeVault, for SourceHut</p>
<p>Then, yesterday morning, KDE GitLab infrastructure was overwhelmed by another AI crawler, with IPs from an Alibaba range; this caused GitLab to be temporarily inaccessible by KDE developers. I then discovered that, one week ago, an Anime girl started appearing on the GNOME GitLab instance, as the page was loaded. It turns out that it's the default loading page for Anubis, a proof-of-work challenger that blocks AI scrapers that are causing outages. - <a href=\"https://thelibre.news/foss-infrastructure-is-under-attack-by-ai-companies/\">FOSS infrastructure is under attack by AI companies</a>, by Niccol√≤ Venerandi, for LibreNews</p>
</blockquote>
" nil nil "d5fbb42d7b346ab63f660d3c2da42907") (10 (26587 60093 852691 718000) "https://alexschroeder.ch/view/2025-03-20-bot-defence" "2025-03-20 Something about the bot defence is working" nil "Thu, 20 Mar 2025 10:30:09 +0000" "<h1 id=\"2025-03-20-something-about-the-bot-defence-is-working\">2025-03-20 Something about the bot defence is working</h1>
<p>At midnight, there was a surge in activity.
CPU usage went up.</p>
<p><img loading=\"lazy\" src=\"2025-03-20-bot-defence-1.jpg\" alt=\"\" /></p>
<p>Load went up, too. But it stayed within reasonable bounds - less than 4 instead of the more than 80 I have seen in the past.</p>
<p><img loading=\"lazy\" src=\"2025-03-20-bot-defence-2.jpg\" alt=\"\" /></p>
<p>And the number of IP addresses blocked by <code>fail2ban</code> went from 40 to 50.</p>
<p><img loading=\"lazy\" src=\"2025-03-20-bot-defence-3.jpg\" alt=\"\" /></p>
<p>I'm usually sceptical of this because the big attacks are from a far wider variety of IP numbers.
In this case, however, maybe there was some probing that resulted in blocks? I don't know. Lucky, I guess?</p>
<p>In any case, the site is still up. Yay for small wins.</p>
<p>Also, I cannot overstate how good it feel to have some <a href=\"https://munin-monitoring.org/\">Munin</a> graphs available.</p>
<p><code>alex-bots</code> is a setup I desribed in <a href=\"2025-02-19-bots-again\">2025-02-19 Bots again, cursed</a>.
Basically a request to one of my Oddmuse wikis containing the parameter <code>rcidonly</code> is an expensive endpoint: ``all changes for this single page'' or ``a feed for this single page''. This is something a human would rarely access and yet it somehow the URLs landed in some dataset for AI training, I suspect. So what I do is I‚Äôm redirecting any request containing ‚Äúrcidonly‚Äù in the query string to <code>/nobots</code>, warning humans not to click on these links.</p>
<p>In addition to that, the filter <code>/etc/fail2ban/filter.d/alex-bots.conf</code> contains this:</p>
<pre><code>[Definition]
failregex = ^(www\\.emacswiki\\.org|communitywiki\\.org|campaignwiki\\.org):[0-9]+ <HOST> .*rcidonly=
</code></pre>
<p>And I added a section using this filter to my jail <code>/etc/fail2ban/jail.d/alex.conf</code>:</p>
<pre><code>[alex-bots]
enabled = true
port    = http,https
logpath = %(apache_access_log)s
findtime = 3600
maxretry = 2
</code></pre>
<p>So if an IP number visits three URLs containing ``rcidonly'' in an hour, they get banned for ten minutes.</p>
<p>The <code>recidive</code> filter (a standard filter you just need to activate) then makes sure that any IP number that got blocked three times gets blocked for a week.</p>
<p><a class=\"tag\" href=\"/search/?q=%23Administration\">#Administration</a> <a class=\"tag\" href=\"/search/?q=%23Butlerian_Jihad\">#Butlerian Jihad</a></p>
" nil nil "1304bd9c10457fdabb9ec59f6f7683cc") (9 (26587 60093 852442 355000) "https://alexschroeder.ch/view/2025-03-19-touch-ground" "2025-03-19 Grounding myself" nil "Wed, 19 Mar 2025 16:31:15 +0000" "<h1 id=\"2025-03-19-grounding-myself\">2025-03-19 Grounding myself</h1>
<p>The powerlessness when reading the news makes me think that perhaps I need to read even less news, shut it all out.</p>
<p>I also find a new appreciation for all of my ancestors who bore children and raised them even though their world seems like a hellscape compared to what I'm seeing.</p>
<p>Sometimes I wish I could just go to church and sing and pray and it would all be good again. Except it don't believe in it.</p>
<p>So all I have is plants and animals to care for. In a somewhat unhealthy (?) relationship with life around me I find that I put plants where they need me to water them, and find solace in the fact that they at least are unperturbed by everything and are just happy for me to be there and tend them. It feels a bit like an artificial dependent relationship so I dunno, it's weird.</p>
<p>When I see happy dogs and their owners I keep thinking that a dog that's so happy to see me, to fetch that ball, to for that walk, this happiness is real, and they are grounded in life and the present moment.</p>
<p>I want back this ignorant bliss of childhood, some days.</p>
<p>I have no illusions. While I grew up, Iran and Iraq were at war; the Mo√ßambique and Angolan wars of independence turned into civil wars; Yugoslavia fell apart in civil war. Those are the conflicts I remember, in any case.
Life and the news wasn't great. I just didn't know.</p>
<p><a class=\"tag\" href=\"/search/?q=%23Life\">#Life</a></p>
" nil nil "006ae765016095b8ad6cea1c5929b0dd") (8 (26587 60093 852227 472000) "https://alexschroeder.ch/view/2025-03-16-memories" "2025-03-16 Klingnauer Stausee" nil "Sun, 16 Mar 2025 23:19:53 +0000" "<h1 id=\"2025-03-16-klingnauer-stausee\">2025-03-16 Klingnauer Stausee</h1>
<p>We walked around the lake, me, my wife, my stepmother and her partner. It was late 2020 and the COVID-19 pandemic was ongoing. I remember having masks on the train and only taking them off as we were walking around the lake.</p>
<p><img loading=\"lazy\" src=\"2025-03-16-memories-8.jpg\" alt=\"\" />
<img loading=\"lazy\" src=\"2025-03-16-memories-9.jpg\" alt=\"\" />
<img loading=\"lazy\" src=\"2025-03-16-memories-1.jpg\" alt=\"\" />
<img loading=\"lazy\" src=\"2025-03-16-memories-2.jpg\" alt=\"\" />
<img loading=\"lazy\" src=\"2025-03-16-memories-3.jpg\" alt=\"\" />
<img loading=\"lazy\" src=\"2025-03-16-memories-4.jpg\" alt=\"\" />
<img loading=\"lazy\" src=\"2025-03-16-memories-6.jpg\" alt=\"\" />
<img loading=\"lazy\" src=\"2025-03-16-memories-7.jpg\" alt=\"\" />
<img loading=\"lazy\" src=\"2025-03-16-memories-5.jpg\" alt=\"\" /></p>
<p><a class=\"tag\" href=\"/search/?q=%23Pictures\">#Pictures</a></p>
" nil nil "4ea535c6d69ac82893f73d6d876021a2") (7 (26587 60093 851973 20000) "https://alexschroeder.ch/view/2025-03-15-canada" "2025-03-15 Canada" nil "Sat, 15 Mar 2025 23:16:54 +0000" "<h1 id=\"2025-03-15-canada\">2025-03-15 Canada</h1>
<p>Today I saw somebody posting a message about Trump's threats to annex Canada from a friend that wanted to remain anonymous. It seems pretty important to me because that's how every former friend of the US is going to react. Greenland is an autonomous territory in the Kingdom of Denmark. Denmark is part of Europe. Denmark spent a lot to support Ukraine. The USA threatened to abandon Ukraine. Both Denmark and Canada are part of NATO. The USA is not behaving like a friend and ally. Not at all.</p>
<p>Trump is a Russian asset.</p>
<p>People will remember.</p>
<p>For reference, aid to Ukraine:</p>
<p><img loading=\"lazy\" src=\"ukraine-aid-2025.jpg\" alt=\"\" /></p>
<p>The US has contributed $69bn, Europe has contributed $66bn, the biggest contributors being Germany with $13.6bn, UK with $10.8bn, Denmark with $8.1bn, and so on. Source: <a href=\"https://www.ifw-kiel.de/topics/war-against-ukraine/ukraine-support-tracker/\">Kiel Institute for the World Economy: War against Ukraine</a>.</p>
<p>Here's the message I mentioned at the top:</p>
<blockquote>
<p>One thing I've learned over the past few weeks, and it's been a bit of a sobering lesson, is that a lot of Americans I know don't actually know what's going on between the US and Canada right now, and just how seriously Canadians are taking this. So, against my better judgement, here's a timeline to explain why we're here, and why we're angry.</p>
<p>Nov 30th, 2018. The United States, Canada and Mexico finalize a trade agreement. Trump personally negotiates the terms and signs the document, celebrating it as `the greatest trade agreement in history''. (This is important.)</p>
<p>Nov 29th, 2024. In a face to face meeting, Trump threatens the Canadian Prime Minister, Justin Trudeau, that he will be imposing 25% tariffs and that if Canada wants to avoid that, it should join the US as a state.</p>
<p>Nov 30th, 2024. Trump publicly calls our Prime Minister `Governor Trudeau' and instructs his staff to only address him as Governor going forward. He again suggests Canada should join the USA.</p>
<p>Dec 3rd, 2024. Trump remarks that he would split Canada into two states once annexed.</p>
<p>Dec 10th, 2024. Trump posts that the majority of Canadians support annexation, despite public polling that only 13% of Canadians would consider the idea.</p>
<p>Dec 18th, 2024. Trump again falsely states that the majority of Canadians support annexation and that one of his lapdogs, Wayne Gretzky, should have a leadership role in that new scenario.</p>
<p>Jan 7th, 2025. At a press conference, Trump says that he would use economic force to destroy the Canadian economy to annex it.</p>
<p>Jan 14, 2025. Trump again claims that most Canadians want to be American, despite new polls showing only 10% of us are open to the idea.</p>
<p>Jan 20th, 2025. During his inaugural address, Trump says that the U.S. will `expand its territory' during his second term.</p>
<p>Jan 23rd, 2025. At the World Economic Forum, Trump says that Canada can avoid tariffs and economic collapse if it joins the US. He says this in front of representatives from most countries in the world.</p>
<p>Jan 24th, 2025. Trump states publicly that Canada `will' become a state</p>
<p>Jan 31st, 2025. Trump announces a 25% tariff on all Canadian imports to begin the next day.</p>
<p>Feb 2nd, 2025. Trump refers to Canada as its `Cherished 51st state' and that it should join the US to avoid tariffs.</p>
<p>Feb 3rd, 2025. A one month delay is agreed upon. Trump, in a conversation with Trudeau states that he doesn't think existing border treaties with Canada are valid, and need to be revised.</p>
<p>Feb 7th, 2025. In a closed door meeting with his cabinet, Prime Minister Trudeau is recorded, without his knowledge, telling everyone that he believes very strongly that Trump is serious and that he stated his reason for annexation as Canadian resources.</p>
<p>Feb 9th, 2025. In a Super Bowl pre-game interview, Trump says that he's serious about his threats, calling it a `viable consideration for expanding US territory'</p>
<p>Feb 10th, 2025. Trump announces an additional 25% tariffs on steel and aluminum imports from Canada to come into effect March 12th.</p>
<p>Feb 24th, 2025. Trump publicly remarks that whoever signed the USMCA agreement is an idiot. He was the one that signed it.</p>
<p>March 4th, 5th, and 6th 2025. Tariffs come into effect. Canada retaliates with it's own tariffs. Tariffs are again postponed until April 1st after a huge market backlash.</p>
<p>March 4th, 2025. In an address to a joint session of congress, Trump states that the US will own Greenland `one way or the other'.</p>
<p>March 5th, 2025. US Secretary of Commerce Howard Lutnick told Canadian finance minister Dominic LeBlanc that Trump ``had come to realize that the relationship between the United States and Canada was governed by a slew of agreements and treaties that were easy to abandon.''</p>
<p>March 7th, 2025. Unconfirmed Memorandum and maps leaked on twitter reveal Trump is allegedly planning to annex the entirety of the great lakes and Southern Ontario, home to 13,491,332 Canadians. This amounts to 35.25% of Canada's total population and includes its largest city, Toronto. This region accounts for 38% of the Canadian economy, and its loss would make Canada's independence functionally impossible.</p>
<p>March 8th, 2025. Canada's foreign minister warns European allies that their government considers Canada to be under existential threat.</p>
<p>March 9th, 2025. Mark Carney, the new Canadian Prime Minister, in his acceptance speech, states that Trump is seeking to destroy Canada, and its way of life.</p>
<p>March 11, 2025. President Trump threatens to ‚Äúpermanently shut down the automobile manufacturing business in Canada‚Äù if Canada does not drop a 250% to 390% tariff on U.S. dairy products, which he doesn‚Äôt state only kicks in after a certain quantity of tariff-free U.S. dairy enters Canada, a quantity that was originally negotiated and agreed to by Trump during the USMCA in 2018.</p>
<p>In Trump's own words, ``The only thing that makes sense is for Canada to become our cherished Fifty First State. This would make all Tariffs, and everything else, totally disappear.</p>
<p>Canadians‚Äô taxes will be very substantially reduced, they will be more secure, militarily and otherwise, than ever before, there would no longer be a Northern Border problem, and the greatest and most powerful nation in the World will be bigger, better and stronger than ever ‚Äî And Canada will be a big part of that. The artificial line of separation drawn many years ago will finally disappear, and we will have the safest and most beautiful Nation anywhere in the World ‚Äî And your brilliant anthem, ‚ÄúO Canada,‚Äù will continue to play, but now representing a GREAT and POWERFUL STATE within the greatest Nation that the World has ever seen!''</p>
<p>March 11th, 2025 PT. II. Peter Navarro, a Senior Advisor for Trump is interviewed by MSNBC. When asked about the tariffs he responds with ``Just tamp it down, please, over there, ok? They're throwing down the hockey gloves. Stop that rhetoric#we're not going to tolerate anything but them stopping killing Americans'', insinuating that this situation was caused by Canadians killing Americans.</p>
<p>March 11th, 2025 PT III. Trump again publicly muses that Canada, Greenland, and the US should be one country, and questions the validity of the Canadian and American border.</p>
<p>To my American friends, I know most of you are amazing and generous people. You didn't ask for this, and I understand that. I hold no ill will towards you, whatsoever. But I must stress, with as much seriousness as I can, the amount of damage this has done.</p>
<p>We have viewed you as our closest friend and ally for a century. We thought of you as brothers and sisters. We answered the call, again and again, for any support you needed from us. Most of Canadians visit the USA so much that we've seen more of the US than we have the rest of Canada.</p>
<p>American products have been taken off our shelves. Canadians are cancelling travel plans to the US. Photo after photo has been shared on social media of empty flights from Canada to the USA.</p>
<p>This isn't a joke to us. We're not overreacting. We don't think he's just saying this shit to cause chaos or negotiate a deal. We wholeheartedly believe that our closest ally and friend is about to bring violence across our border, economically destroy us, and eliminate our way of life.</p>
<p>The main driver for Canada's creation in 1867 was SPECIFICALLY to not be part of America, and to end America's very public threats and plans to annex our territory.</p>
<p>We're angry. We're really, really fucking angry. Open your eyes to what's happening because we're tired of trying to make you understand why and asking you why it seems like none of you care. **</p>
<p>I still hope that there is time to repair this. I still believe that this is the result of one man's plan to burn it all down. But time is running out, and fast.</p>
<p>- Anonymous</p>
</blockquote>
<p><a class=\"tag\" href=\"/search/?q=%23USA\">#USA</a> <a class=\"tag\" href=\"/search/?q=%23Canada\">#Canada</a> <a class=\"tag\" href=\"/search/?q=%23Trump\">#Trump</a></p>
" nil nil "c4f48bfff8bd3cca4f3290858e8711cb") (6 (26587 60093 851157 542000) "https://alexschroeder.ch/view/2025-03-15-niri" "2025-03-15 New window manager: niri" nil "Wed, 19 Mar 2025 13:20:51 +0000" "<h1 id=\"2025-03-15-new-window-manager-niri\">2025-03-15 New window manager: niri</h1>
<p>I'm giving <a href=\"https://github.com/YaLTeR/niri\">niri</a> a go.
The idea is that a scrollable tiling window manager
(``Wayland compositor'') is a better fit than just a tiling window manager.
For tiling window managers, I just create new stuff and have it maximized.
I really can't do the quick splitting and rearranging that it seems to afford.
The result is that I start moving stuff to other workspaces, where they're
invisible and gone.
I'm hoping that new windows popping up next to existing windows makes it feel
like a stack.</p>
<p>Having gone through the config file and having made a few small changes it
already feels pretty nice. Right now one of the problems I have is that
by sheer bad luck I decided to rotate my external monitor by 90¬∞ and that
doesn't work quite as well, maybe? I'm not sure. One of the first changes
I did was change the default widths from ‚Öì / ¬Ω / ‚Öî to 0.95 / ‚Öî / ¬Ω with 0.95 being
the default.</p>
<p><a class=\"tag\" href=\"/search/?q=%23Window_Managers\">#Window Managers</a> <a class=\"tag\" href=\"/search/?q=%23Niri\">#Niri</a></p>
<p>I didn't find a solution for Gimp. And I already had no solution for VASSAL under Sway. So for these applications, I still have Gnome installed.</p>
<p>Currently my <code>~/.config/fish/conf.d/window-manager.fish</code> says:</p>
<pre><code># If running from tty1 start sway
set TTY (tty)
[ \"$TTY\" = \"/dev/tty1\" ] && exec sway
[ \"$TTY\" = \"/dev/tty2\" ] && exec startx
[ \"$TTY\" = \"/dev/tty3\" ] && exec niri
</code></pre>
<p>Oh well. üòÖ</p>
<p><strong>2025-03-19</strong>. I'm finding that there were too many problems with apps that didn't work or had very slow startup times. So I'm back to <a href=\"2023-10-22-sway\">using Sway</a>.</p>
" nil nil "dd6a88ed6b3330528988354f62633daf") (5 (26587 60093 850910 879000) "https://alexschroeder.ch/view/2025-03-14-fado" "2025-03-14 Fado on Bandcamp" nil "Fri, 14 Mar 2025 22:19:17 +0000" "<h1 id=\"2025-03-14-fado-on-bandcamp\">2025-03-14 Fado on Bandcamp</h1>
<p>I heard about <a href=\"https://linaralrefree.bandcamp.com/album/lina-ra-l-refree\">Lina_Ra√ºl Refree</a>, yesterday, bought it, and I've been listening to it.
Today I'm listening to <a href=\"https://linafado.bandcamp.com/album/fado-cam-es\">Fado Cam√µes</a> by LINA.</p>
<p>Also bought:</p>
<ul>
<li><a href=\"https://lheuredeschiens.bandcamp.com/album/jusquici-tout-va-bien\">Jusqu'ici tout va bien</a> by L'heure des chiens</li>
<li><a href=\"https://cristinabranco.bandcamp.com/album/m-e\">m√£e</a> by Cristina Branco</li>
<li><a href=\"https://claudia-aurora.bandcamp.com/album/mulher-do-norte\">Mulher do Norte</a> by Claudia Aurora</li>
</ul>
<p>Let me know if you have other suggestions.</p>
<p>I should put some on T√™tes raides.</p>
<p><a class=\"tag\" href=\"/search/?q=%23Music\">#Music</a></p>
" nil nil "29eaa7a86d20222c52e07d53b6cd1641") (4 (26587 60093 850635 637000) "https://alexschroeder.ch/view/2025-03-13-calc" "2025-03-13 Calculators and spreadsheets" nil "Thu, 13 Mar 2025 22:45:10 +0000" "<h1 id=\"2025-03-13-calculators-and-spreadsheets\">2025-03-13 Calculators and spreadsheets</h1>
<p>I stumbled upon a discussion about the Gnome Calculator. Apparently it stopped working for some people because a bank blocked it from retrieving the exchange rates it needs to allow users to do currency conversions. I get it. It's a feature, it needs data that's up to date, so you need to fetch it. The default is to do this once a week, I hear.</p>
<p>Based on <a href=\"https://gitlab.gnome.org/GNOME/gnome-calculator/-/blob/main/lib/currency-provider.vala\">currency-provider.vala</a>, the currency providers are the <a href=\"https://www.imf.org/external/np/fin/data/rms_five.aspx\">International Monetary Fund</a> (IMF) and the <a href=\"https://www.ecb.europa.eu/stats/eurofxref/eurofxref-daily.xml\">European Central Bank</a>.</p>
<p>So that leads me to another question: What do you use to do calculations you can't do in your head?</p>
<p>I mostly do it in Emacs using <code>M-x calc</code>. It uses the reverse-polish notation (RPN) I am used to from my old calculators before there where smartphones.
For a while I used <code>bc</code> but the precision was weird. Then I tried <code>dc</code> but it was weird, too. Now I have Super+C bound to <code>orpie</code> running in a terminal. Perhaps I should bind that key to run <code>emacsclient</code> and eval <code>(calc)</code>. üòÇ</p>
<p>From the replies, I found a large number of people reporting that they used the interpreters of their favourite programming languages. I didn't know that this was so wide-spread. People named Python, Ruby, Fennel, Scheme.</p>
<p>Python:</p>
<pre><code>Python 3.11.2 (main, Nov 30 2024, 21:22:50) [GCC 12.2.0] on linux
Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.
>>> 1+2+3
6
</code></pre>
<p>Ruby:</p>
<pre><code>irb(main):001:0> 1+2+3
=> 6
</code></pre>
<p>Fennel:</p>
<pre><code>Welcome to fennel!
>> (+ 1 2 3)
6
</code></pre>
<p>Chicken Scheme:</p>
<pre><code>CHICKEN
(c) 2008-2021, The CHICKEN Team
(c) 2000-2007, Felix L. Winkelmann
Version 5.3.0 (rev e31bbee5)
linux-unix-gnu-x86-64 [ 64bit dload ptables ]
Type ,? for help.
#;1> (+ 1 2 3)
6
</code></pre>
<p><a class=\"account\" href=\"https://nrw.social/@HaraldKi\" title=\"@HaraldKi@nrw.social\">@HaraldKi</a> shared that they use a shell, but not just any shell: <code>tclsh</code> with the <a href=\"https://www.tcl-lang.org/man/tcl8.4/TclCmd/expr.htm\">expr</a> built-in command.</p>
<blockquote>
<p>Tclsh uses just double math, afair, and understands plain and simple everyday expressions you basically learned in primary school. Plus scientific notation like 2.7e22 . Plus a chunk of log, sin, cos, tan if really needed. So no brain tweaks needed. The only thing to keep in mind: add .0 to most numbers to not accidentally get ¬æ -> 0.</p>
</blockquote>
<p>The key is have a function in your shell that gets transformed into a Tcl command that is piped to <code>tclsh</code>.
In my case, using <code>fish</code>, use <code>funced calc --save</code> and use the following:</p>
<pre><code>function calc
echo \"puts [expr {$args}]\" | tclsh
end
</code></pre>
<p>At the shell prompt:</p>
<pre><code>> calc 1+2+3
6
> calc 4/3
1
> calc 4/3.0
1.3333333333333333
</code></pre>
<p>What about the other options?</p>
<p>I think the key is that they have to startup fast and be ready to type.
<code>bc</code> certainly qualifies.
Just remember to set the scale!
Or use the <code>--mathlib</code> option.</p>
<pre><code>bc 1.07.1
Copyright 1991-1994, 1997, 1998, 2000, 2004, 2006, 2008, 2012-2017 Free Software Foundation, Inc.
This is free software with ABSOLUTELY NO WARRANTY.
For details type `warranty'.
1+2+3
6
4/3
1
scale=3
4/3
1.333
</code></pre>
<p><code>dc</code> has reverse-polish notation (RPN) but is very terse.
Tokens are separated by spaces or newlines.
Thus, the Enter key doesn't print a result. You need to use the <code>p</code> command.
Again, the default is integer math.
Use the <code>k</code> command to switch scale.</p>
<pre><code>1 2 3 + + p
6
4 3 / p
1
3 k 4 3 / p
1.333
</code></pre>
<p>A weird part is that you need to enter negative numbers using the underscore (<code>_3</code> for -3).</p>
<p>By contrast, my favourite calculator in the terminal right now is <code>orpie</code>.
You get reverse-polish notation and immediate feedback.</p>
<pre><code>Orpie v1.6.1 -- swap drop dup view    | 25:
--------------------------------------| 24:
Calculator Modes:                     | 23:
angle: RAD  base: DEC  complex: REC | 22:
| 21:
Common Operations:                    | 20:
enter    : <return>                 | 19:
drop     : \\                        | 18:
swap     : <pagedown>               | 17:
backspace: \\177                     | 16:
add      : +                        | 15:
subtract : -                        | 14:
multiply : *                        | 13:
divide   : /                        | 12:
y^x      : ^                        | 11:
negation : n                        | 10:
Miscellaneous:                        |  9:
scientific notation     : <space>   |  8:
abbreviation entry mode : '         |  7:
stack browsing mode     : <up>      |  6:
refresh display         : C-L       |  5:
quit                    : Q         |  4:
|  3:
|  2:                                   6
|  1:                    1.33333333333333
--------------------------------------------------------------------------------
</code></pre>
<p>Emacs comes with <code>M-x quick-calc</code> which simply asks for an expression and prints the result:</p>
<pre><code>Result: 1 + 2 + 3 =>  6  (16#6, 8#6, 2#110, \"^F\")
</code></pre>
<p>Then there's <code>M-x calculator</code> which comes with its own mode. You can use <code>o h</code> to switch output to hex, for example. So adding up 1 + 2 + 3 + 4 results in 10, or A in hex.</p>
<pre><code>Calc==H> A
</code></pre>
<p>And finally there is <code>M-x calc</code>.
Check out the <a href=\"https://github.com/ahyatt/emacs-calc-tutorials/blob/master/README.org\">short tutorials</a> by Andrew Hyatt, if you're interested in learning more.
As I said above, this is my default solution. <code>1 RET 2 RET 3 RET + +</code> and there we go. Plus a trail over on the right in case you're confused.</p>
<pre><code>---------------------- Emacs Calculator Mode ---------------------- |----- Emacs Calculator Trail -----
1:  6                                                               |     1
.                                                               |     2
|     3
|   + 5
|   +>6
|
|
-UUU:%*--F1  Calc: 12 Deg    All L2     (Calculator) ---------------|-UUU:%*--F1  *Calc Trail*   All L5
</code></pre>
<p>Copying the result runs into a tiny problem, for me: The stack depth is copied along with it! So if you copy the above result (6), what you actually get is <code>1: 6</code>. Which is never what I want to paste elsewhere. Never.</p>
<p><a class=\"account\" href=\"https://sfba.social/@kickingvegas\" title=\"@kickingvegas@sfba.social\">@kickingvegas</a> suggested <a href=\"https://github.com/kickingvegas/casual?tab=readme-ov-file#calc-elisp-library-casual-calc\">casual-calc</a>, which is part of ``a project to re-imagine the primary user interface for Emacs using keyboard-driven menus''.</p>
<p><a class=\"account\" href=\"https://helvede.net/@m\" title=\"@m@helvede.net\">@m</a> suggested <a href=\"https://qalculate.github.io/\">qcalc</a> which also offers ‚Äúcurrency conversion‚Äù:</p>
<blockquote>
<p>The exchange rates can be updated manually using File ‚Üí Update Exchange Rates, or automatically at specific intervals (by default once every week, but this can be changed in the preferences dialog), when needed (when currencies are converted).</p>
</blockquote>
<p>Apparently it gets the exchange rates from the European Central Bank and Coinbase App APIs.</p>
<p>Another option is spreadsheets, of course.
<a class=\"account\" href=\"https://merveilles.town/@neauoire\" title=\"@neauoire@merveilles.town\">@neauoire</a> mentioned <a href=\"https://wiki.xxiivv.com/site/nebu\">nebu</a>.
I don't have a Varvara system up and running, however.</p>
<p>There is <code>sc</code>, of course.
If you don't want to hit <code>=</code> for every number you enter, use <code>-n</code> for ``quick numeric entry''.
I'm not sure how I can quickly select the range for something like <code>@sum(A0:A2)</code> but it certainly seems possible to use <code>sc</code> for interesting stuff.</p>
<pre><code>B2 (10 2 0) [B0/B1]
A         B         C         D         E         F         G
0       1.00      4.00
1       2.00      3.00
2       3.00      1.33
3       6.00
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
</code></pre>
<p>Visidata (<code>vd</code>) also looks interesting. Sadly I have no idea how to do anything. üòÇ</p>
<pre><code>  File  Edit  View  Column  Row  Data  Plot  System  Help     Ctrl+H for help menu
directory          ‚îÇ filename           ‚ïë ext                ‚îÇ size              #‚îÇ modtime
1‚Ä∫ .|                                                              BUTTON1_RELEASED   no-op 0 files  ‚Ä¢0
</code></pre>
<p>Of course, Emacs also comes with a spreadsheet. Visit an empty file ending with <code>.ses</code>.
Enter a number. To add a new row, use <code>down</code> then create a new cell using <code>TAB</code> and enter a second number.
When you need a formula, use <code>(apply ses+ (ses-range A1 A3))</code>, for example.</p>
<pre><code>File Edit Options Buffers Tools SES Help
A       B       C       D
1
2
3
6
</code></pre>
<p><a class=\"tag\" href=\"/search/?q=%23Calculators\">#Calculators</a> <a class=\"tag\" href=\"/search/?q=%23Spreadsheets\">#Spreadsheets</a> <a class=\"tag\" href=\"/search/?q=%23Software\">#Software</a></p>
" nil nil "17428377d23d75a51b1fb96973105368") (3 (26587 60093 849610 713000) "https://alexschroeder.ch/view/2025-03-11-us-arms" "2025-03-11 Distrusting US arms dealers" nil "Tue, 11 Mar 2025 11:04:58 +0000" "<h1 id=\"2025-03-11-distrusting-us-arms-dealers\">2025-03-11 Distrusting US arms dealers</h1>
<p>Ah, this is where the quotes come from:</p>
<blockquote>
<p>He‚Äôs done everything to discredit and demean Zelensky on the international stage with the shameful press conference in which he teamed up with the vice president to attack Zelensky,‚Äù said Sen. Jeff Merkley (D-Ore.). He pressed Whitaker, and other State Department nominees in the hearing, over whether Trump is a Russian asset. ‚ÄúWhat else could a Russian asset actually possibly do that Trump hasn‚Äôt yet done? ‚Äì <a href=\"https://thehill.com/homenews/senate/5175978-matthew-whitaker-nato-trump/\">Trump‚Äôs NATO nominee commits to alliance, despite MAGA opponents</a>, by Laura Kelly, for The Hill</p>
</blockquote>
<p>In the same piece:</p>
<blockquote>
<p>Moreover ‚Äî people should not assume that Trump‚Äôs policies are destructive for NATO. If anything, pushing European allies to increase defense spending is going to strengthen NATO.</p>
</blockquote>
<p>Well, I'm assuming that a NATO full of bootlickers would be great for Trump as he and Putin divvy up Europe.</p>
<p>I bet every European country that bough US equipment is super angry right now.</p>
<p>I am super angry because Switzerland, after a long fight against the new fighter planes, after considering Swedish and French fighter planes, decided to go with the planes that are the most expensive, the most unreliable (based on my uninformed opinions), and the most untrustworthy: the F-35.</p>
<p>From a country that bullies its allies and betrays its friends, that switches off the satellite phones, the intelligence sharing, and whatever else it damn pleases in order to force a settlement. Which is within their rights, of course. But also disqualifies them as a friend for a generation, if you ask me.</p>
<p>A country with the most powerful military in the world and the wisdom of a tooth that needs to be pulled. ü§Æ</p>
<p>And we're not even part of NATO.</p>
<p>‚ÅÇ</p>
<p>For more about the F-35, <a class=\"account\" href=\"https://agora.echelon.pl/users/kravietz\" title=\"@kravietz@agora.echelon.pl\">@kravietz</a> recently linked to this article:</p>
<blockquote>
<p>With over 400 F-35s projected for Europe by 2030, per Lockheed Martin, the jet remains a cornerstone of NATO‚Äôs air power‚Äîbut its integration highlights a paradox: its technological edge comes at the cost of strategic vulnerability. The U.S. policy restricting independent test operations outside CONUS, combined with reliance on U.S.-managed MDFs, ALIS, ODIN, and software updates, amplifies fears of over-dependence. - <a href=\"https://theaviationist.com/2025/03/10/f-35-kill-switch-myth/\">The F-35 ‚ÄòKill Switch‚Äô: Separating Myth from Reality</a></p>
</blockquote>
<p><a class=\"account\" href=\"https://agora.echelon.pl/users/kravietz\" title=\"@kravietz@agora.echelon.pl\">@kravietz</a> adds:</p>
<blockquote>
<p>‚Ä¶ but the problem is not technical. The problem is that in 2025 US has rather clearly signalled that its subjectively defined ‚Äúinterests‚Äù will now have priority of international agreements.</p>
<p>That is, the same agreements towards which the US has over the 30 years consistently pushed all European countries, and especially the new EU and NATO joiners. And it made sense as long as the US was the guarantor of these treaties.</p>
<p>What we have now? Let‚Äôs say Russia conducts a limited military incursion into eastern Poland with the objective of controlling the Suwalki Corridor. This of course is in violation of UN Charter, NATO Charter and a hundred of bilateral treaties between Russia and EU and Poland. So what? The 2025 US president now decides a ‚Äúprolonged defense‚Äù is ‚Äúnot in US interests‚Äù and does everything to force ‚Äúpeace‚Äù on Poland.</p>
<p>‚ÄúEverything‚Äù includes impairing US-delivered weapons systems and generally creating a powerful impression of stab in the back.</p>
<p>A ‚Äúpeace‚Äù, in which Poland‚Äôs concession is the town of Suwa≈Çki, and Russia‚Äôs ‚Äúconcession‚Äù is the nearby town of Olsztyn, which Russia mercifully agrees not to occupy or destroy. Well, it also happens to be a Polish town but Russia in the meantime declared it ‚Äúhistorically Russian region‚Äù and it now presents it as a concession.</p>
<p>And the 2025 US president says it‚Äôs OK, because ‚Äúpeace‚Äù and ‚Äúboth sides did concessions‚Äù.</p>
</blockquote>
<p><a class=\"tag\" href=\"/search/?q=%23Russia\">#Russia</a> <a class=\"tag\" href=\"/search/?q=%23Poland\">#Poland</a> <a class=\"tag\" href=\"/search/?q=%23NATO\">#NATO</a></p>
" nil nil "2e63a02ec32e9dc8887c2eb60322d1f6") (2 (26587 60093 849007 581000) "https://alexschroeder.ch/view/2025-03-11-chainsaw-politicians" "2025-03-11 Chainsaw politicians" nil "Tue, 11 Mar 2025 11:01:51 +0000" "<h1 id=\"2025-03-11-chainsaw-politicians\">2025-03-11 Chainsaw politicians</h1>
<p>Recovery from DOGE is hard.</p>
<p>To put recovery from DOGE into perspective: In tiny Switzerland we elected prime right-winger Blocher into government and he ran the justice department for a handful years. And he fired a lot of people for efficiency. And the institutions are still struggling twenty years later. People fired find new jobs, new careers, early retirements. People staying work hard, burn out, are angry, work on projects and switch tracks before the projects run into walls. The institutional memory keeps shrinking as the new recruits are younger and younger. Suddenly the seniors have been here for just four years. It‚Äôs a disgrace. A festering wound. All the jobs are overwhelming and people are drained when they take these positions and they leave again or burn out or struggle or backstab.</p>
<p>And of course everybody who was against the cuts isn‚Äôt automatically in favour of increasing the budgets and raising taxes when the chainsaw politicians are gone. But the jobs still needs to get done and so quality goes down and waiting times increase and you can all join the slow march of institutional death and hope for that rekindling of the founding spirit, when having working institutions are a goal again, when the empathy-deprived scrooges are long gone.</p>
<p><a class=\"tag\" href=\"/search/?q=%23Switzerland\">#Switzerland</a> <a class=\"tag\" href=\"/search/?q=%23USA\">#USA</a></p>
" nil nil "f8c2b2bbbcc0e3c6830ed3e93083983d") (1 (26587 60093 848579 962000) "https://alexschroeder.ch/view/2025-03-09-discord-ipo" "2025-03-09 The looming Discord IPO" nil "Tue, 11 Mar 2025 12:35:10 +0000" "<h1 id=\"2025-03-09-the-looming-discord-ipo\">2025-03-09 The looming Discord IPO</h1>
<p>So# Discord might be going there. I like their offering. I even pay them about $10/month.
What they offer works well.
People get their own little communities to administer, with the tools to administer them well, with the self-written automations and bots to handle communities from a handful of people to many thousands.
Read <a class=\"account\" href=\"https://infosec.exchange/@isotopp\" title=\"@isotopp@infosec.exchange\">@isotopp</a>‚Äôs <a href=\"https://infosec.exchange/@isotopp/114116202418228034\">perspective on Discord</a>.</p>
<p>But the monetization drive is strong.
And once the shareholders are in place, pressure for monetization will ramp up even more, I'm sure. How long until it all goes down? Five years?</p>
<p>What are your backup plans?</p>
<p><a href=\"https://campaignwiki.org/wiki/Chat\">My backup plan</a> is an IRC backend (<a href=\"https://ngircd.barton.de/\">ngircd</a> uses about 5M of memory) and two instances of a web front-end called <a href=\"https://thelounge.chat/\">The Lounge</a>. One of them is free for all and connects to my chat server; the other needs registration and offers file uploads and always-on connectivity (it acts as a ``bouncer''). The two of them take about 150M of memory. Each registered account gets a little SQLite file with the logs. No other resources required.</p>
<p>You can connect to the IRC backend directly using your favourite IRC client, of course. Emacs comes with two of them. Just saying. üòÑ</p>
<p>For iOS, there's <a href=\"https://colloquy.app/\">Colloquy</a>.</p>
<p>For Android, <a class=\"account\" href=\"https://tabletop.social/@wandererbill\" title=\"@wandererbill@tabletop.social\">@wandererbill</a> suggests <a href=\"https://f-droid.org/packages/io.mrarm.irc/\">Revolution IRC</a>.</p>
<p><a class=\"account\" href=\"https://tabletop.social/@phf\" title=\"@phf@tabletop.social\">@phf</a> suggested <a href=\"https://snikket.org/service/quickstart/\">Snikket</a> instead. Installation requires a Docker image.</p>
<p>I dislike Docker, not because of what it is but because of what it implies. A virtual machine inside your virtual machine means that it doesn't auto-update. Upgrading will be tricky. It also means individual deployment requires multiple services such that it ended up being easier for them to supply a Docker image instead of supplying good instructions. I always take that to mean that the setup is brittle and underdocumented. Perhaps I‚Äôm wrong but it that‚Äôs the suspicion I have.</p>
<p>Generally speaking, I dislike Docker images for my virtual server server (6G memory, 75g storage, 2 cores) because multiple services packaged in a dockerfile usually mean lots of resources required. Frugal computing means that I am loath to accommodate that. I prefer not to upgrade my virtual machine.</p>
<p><a class=\"account\" href=\"https://tabletop.social/@phf\" title=\"@phf@tabletop.social\">@phf</a> also suggested <a href=\"https://app.revolt.chat/\">Revolt</a>.
<a class=\"account\" href=\"https://tabletop.social/@wandererbill\" title=\"@wandererbill@tabletop.social\">@wandererbill</a> created a <a href=\"https://rvlt.gg/wkBDhJPb\">Grenzland Server on Revolt</a>.
<a class=\"account\" href=\"https://social.city-of-glass.net/users/cidney\" title=\"@cidney@social.city-of-glass.net\">@cidney</a> noted that it had Discord-like roles and role management for the server owner to hand out, so perhaps it's quite a suitable replacement.
Revolt can be self-hosted via Docker or self-building. At least there is a lot of info out there.
<a class=\"account\" href=\"https://social.city-of-glass.net/users/cidney\" title=\"@cidney@social.city-of-glass.net\">@cidney</a> also found a wiki pages listing only four known instances including the default one, the largest being Andrew Tate's. ü§Æ</p>
<p><a class=\"account\" href=\"https://tabletop.social/@wandererbill\" title=\"@wandererbill@tabletop.social\">@wandererbill</a> wanted to give Matrix another spin.
There are two server implementations, Synapse and Dendrite.</p>
<blockquote>
<p>At an absolute minimum, Dendrite will expect 1GB RAM. For a comfortable day-to-day deployment which can participate in federated rooms for a number of local users, be prepared to assign 2-4 CPU cores and 8GB RAM ‚Äî more if your user count increases. - <a href=\"https://element-hq.github.io/dendrite/installation/planning\">Planning your installation</a></p>
</blockquote>
<p><a class=\"account\" href=\"https://tabletop.social/users/kyonshi\" title=\"@kyonshi@tabletop.social\">@kyonshi</a> suggested <a href=\"https://jitsi.org/\">Jitsi</a>.
I tried to self-host it a few years ago.
It worked well! But it also took a lot of resource. During the video call, the virtual machine's <a href=\"2020-03-26_Jitsi_and_the_CPU\">load went up to 8</a>.
We sometimes use the installation at the <a href=\"https://ffmuc.net/\">Freifunk M√ºnchen</a> for gaming.
Thanks, ffmuc! üòç</p>
<p>So, where does that leave is? I don't know. People don't seem to like The Lounge with IRC backend and I seem to be unwilling to upgrade my hosting commitments.</p>
<p><a class=\"account\" href=\"https://hackers.town/@mc\" title=\"@mc@hackers.town\">@mc</a> recently recommended a different IRC server called <a href=\"https://ergo.chat/about\">Ergo</a> and a different web front-end called <a href=\"https://codeberg.org/emersion/gamja\">Gamja</a> but it's unclear to me what significant advantages either would offer.</p>
<p>Previously:</p>
<blockquote>
<p>So‚Ä¶ the situation is bad, but I still use Discord. - <a href=\"2022-08-16_Discord\">Discord</a> (2022)</p>
</blockquote>
<p><a class=\"account\" href=\"https://tilde.zone/@dashdsrdash\" title=\"@dashdsrdash@tilde.zone\">@dashdsrdash</a> wrote wrote in with some interesting feedback. The Zulip part is interesting because I only used it for tiny bit, talking to the maintainers of Antora. Here's what they have to say:</p>
<blockquote>
<ul>
<li>Zulip is great for UI, slightly aggravating to run. It absolutely wants a dedicated server. It has a dice roller as one of the sample bots, and the API is extensive.</li>
<li>IRC is extremely easy to setup and relatively easy to write bots for. Interfaces vary from bare bones to not-bad; The Lounge is up on the not-bad end, and also easy to host.</li>
<li>Matrix may be the future of federated chat systems, but if you don't need federation, the complexity and ongoing maintenance are not worth it.</li>
<li>Jitsi has integrated chat but is video-conferencing-centric; the text chat is actually Prosody (an XMPP/Jabber) server under the hood. Video processing takes up a lot of CPU and bouncing it around takes a lot of bandwidth; otherwise, it's pretty nice.</li>
<li>I haven't tried running Revolt but I looked at the docs and I am really not favorably inclined. They have some questionable technology choices and insist on a Docker-first install that in my experience is a likely sign that there are too many moving parts for anyone to be able to diagnose what's going wrong.</li>
</ul>
<p>My suggestions would be:</p>
<ul>
<li>IRC is still a solid choice</li>
<li>Prosody without the Jitsi video conferencing is pretty nice, albeit a little complex to configure initially.</li>
<li>If I felt like spending the money for a medium-large VM at a hosting service dedicated to gaming, Zulip would be nice.</li>
</ul>
</blockquote>
<p>I didn't know about the hosting of Zulip but the rest tracks my experience. IRC is the simplest option.</p>
<p><a class=\"account\" href=\"https://social.vivaldi.net/@randomwizard\" title=\"@randomwizard@vivaldi.net\">@randomwizard</a> is giving <a href=\"https://galene.org/\">Gal√®ne</a> a try. Videoconferencing that might not be as hard to setup correctly as self-hosted Jitsi!</p>
<p><a class=\"tag\" href=\"/search/?q=%23Snikket\">#Snikket</a> <a class=\"tag\" href=\"/search/?q=%23Discord\">#Discord</a> <a class=\"tag\" href=\"/search/?q=%23Revolt\">#Revolt</a> <a class=\"tag\" href=\"/search/?q=%23Matrix\">#Matrix</a> <a class=\"tag\" href=\"/search/?q=%23Jitsi\">#Jitsi</a> <a class=\"tag\" href=\"/search/?q=%23IRC\">#IRC</a> <a class=\"tag\" href=\"/search/?q=%23Chat\">#Chat</a></p>
" nil nil "9814721ff9c54f91818decf5447b9f22")))